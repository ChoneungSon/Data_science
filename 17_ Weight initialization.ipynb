{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    train_data = np.expand_dims(train_data, axis=-1)\n",
    "    test_data = np.expand_dims(test_data, axis=-1)\n",
    "    \n",
    "    train_data, test_data = normalization(train_data, test_data)\n",
    "    \n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def normalization(train_data, test_data):\n",
    "    train_data = train_data.astype(np.float32) / 255.0\n",
    "    test_data = test_data.astype(np.float32) / 255.0\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, from_logits=True))\n",
    "    # from_logits : y_pred 가 logits 인지의 유무\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    prediction = tf.equal(tf.argmax(logits, axis=-1), tf.argmax(labels, axis=-1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten():\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def Dense(label_dim, weight_init):\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu():\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model, self).__init__()\n",
    "        weight_init = tf.keras.initializers.glorot_uniform()\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten())\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.model.add(Dense(256, weight_init))\n",
    "            self.model.add(relu())\n",
    "            \n",
    "        self.model.add(Dense(label_dim, weight_init))\n",
    "        \n",
    "    def call(self, x, training=None, mask=None):\n",
    "        # training 여부를 묻는 training\n",
    "        # tf.keras.model를 상속받아서 생기는 옵션\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_mnist()\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=len(test_data)).\\\n",
    "    batch(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0]/[  468] | train_loss: 2.0816 | train_accuracy: 0.3203 | test_accuracy: 0.2185\n",
      "[    1]/[  468] | train_loss: 2.0510 | train_accuracy: 0.3984 | test_accuracy: 0.3208\n",
      "[    2]/[  468] | train_loss: 1.9042 | train_accuracy: 0.3906 | test_accuracy: 0.3891\n",
      "[    3]/[  468] | train_loss: 1.8139 | train_accuracy: 0.4922 | test_accuracy: 0.4644\n",
      "[    4]/[  468] | train_loss: 1.8149 | train_accuracy: 0.5156 | test_accuracy: 0.5699\n",
      "[    5]/[  468] | train_loss: 1.6218 | train_accuracy: 0.6484 | test_accuracy: 0.6738\n",
      "[    6]/[  468] | train_loss: 1.4578 | train_accuracy: 0.7500 | test_accuracy: 0.7223\n",
      "[    7]/[  468] | train_loss: 1.3399 | train_accuracy: 0.8203 | test_accuracy: 0.7370\n",
      "[    8]/[  468] | train_loss: 1.2483 | train_accuracy: 0.6875 | test_accuracy: 0.7363\n",
      "[    9]/[  468] | train_loss: 1.2308 | train_accuracy: 0.7266 | test_accuracy: 0.7621\n",
      "[   10]/[  468] | train_loss: 1.0475 | train_accuracy: 0.8125 | test_accuracy: 0.7786\n",
      "[   11]/[  468] | train_loss: 0.9551 | train_accuracy: 0.8438 | test_accuracy: 0.7872\n",
      "[   12]/[  468] | train_loss: 0.8473 | train_accuracy: 0.7969 | test_accuracy: 0.7908\n",
      "[   13]/[  468] | train_loss: 0.8837 | train_accuracy: 0.7578 | test_accuracy: 0.7995\n",
      "[   14]/[  468] | train_loss: 0.5942 | train_accuracy: 0.8984 | test_accuracy: 0.8124\n",
      "[   15]/[  468] | train_loss: 0.5869 | train_accuracy: 0.8750 | test_accuracy: 0.8250\n",
      "[   16]/[  468] | train_loss: 0.7102 | train_accuracy: 0.7734 | test_accuracy: 0.8351\n",
      "[   17]/[  468] | train_loss: 0.6213 | train_accuracy: 0.8672 | test_accuracy: 0.8451\n",
      "[   18]/[  468] | train_loss: 0.5507 | train_accuracy: 0.8516 | test_accuracy: 0.8462\n",
      "[   19]/[  468] | train_loss: 0.4187 | train_accuracy: 0.9062 | test_accuracy: 0.8395\n",
      "[   20]/[  468] | train_loss: 0.5709 | train_accuracy: 0.8125 | test_accuracy: 0.8416\n",
      "[   21]/[  468] | train_loss: 0.4947 | train_accuracy: 0.8516 | test_accuracy: 0.8466\n",
      "[   22]/[  468] | train_loss: 0.6106 | train_accuracy: 0.8047 | test_accuracy: 0.8484\n",
      "[   23]/[  468] | train_loss: 0.6452 | train_accuracy: 0.8359 | test_accuracy: 0.8439\n",
      "[   24]/[  468] | train_loss: 0.5751 | train_accuracy: 0.8047 | test_accuracy: 0.8532\n",
      "[   25]/[  468] | train_loss: 0.4660 | train_accuracy: 0.8594 | test_accuracy: 0.8703\n",
      "[   26]/[  468] | train_loss: 0.4656 | train_accuracy: 0.8438 | test_accuracy: 0.8710\n",
      "[   27]/[  468] | train_loss: 0.4028 | train_accuracy: 0.8672 | test_accuracy: 0.8671\n",
      "[   28]/[  468] | train_loss: 0.2993 | train_accuracy: 0.9141 | test_accuracy: 0.8618\n",
      "[   29]/[  468] | train_loss: 0.4807 | train_accuracy: 0.8594 | test_accuracy: 0.8709\n",
      "[   30]/[  468] | train_loss: 0.4343 | train_accuracy: 0.8828 | test_accuracy: 0.8785\n",
      "[   31]/[  468] | train_loss: 0.3622 | train_accuracy: 0.8906 | test_accuracy: 0.8752\n",
      "[   32]/[  468] | train_loss: 0.3902 | train_accuracy: 0.8906 | test_accuracy: 0.8681\n",
      "[   33]/[  468] | train_loss: 0.3793 | train_accuracy: 0.9062 | test_accuracy: 0.8654\n",
      "[   34]/[  468] | train_loss: 0.4098 | train_accuracy: 0.8984 | test_accuracy: 0.8758\n",
      "[   35]/[  468] | train_loss: 0.3750 | train_accuracy: 0.8984 | test_accuracy: 0.8893\n",
      "[   36]/[  468] | train_loss: 0.3869 | train_accuracy: 0.8906 | test_accuracy: 0.8878\n",
      "[   37]/[  468] | train_loss: 0.4008 | train_accuracy: 0.8594 | test_accuracy: 0.8736\n",
      "[   38]/[  468] | train_loss: 0.5365 | train_accuracy: 0.8281 | test_accuracy: 0.8703\n",
      "[   39]/[  468] | train_loss: 0.6025 | train_accuracy: 0.8516 | test_accuracy: 0.8797\n",
      "[   40]/[  468] | train_loss: 0.3940 | train_accuracy: 0.8906 | test_accuracy: 0.8894\n",
      "[   41]/[  468] | train_loss: 0.3611 | train_accuracy: 0.8984 | test_accuracy: 0.8883\n",
      "[   42]/[  468] | train_loss: 0.3496 | train_accuracy: 0.8906 | test_accuracy: 0.8880\n",
      "[   43]/[  468] | train_loss: 0.4019 | train_accuracy: 0.8750 | test_accuracy: 0.8894\n",
      "[   44]/[  468] | train_loss: 0.5195 | train_accuracy: 0.8438 | test_accuracy: 0.8882\n",
      "[   45]/[  468] | train_loss: 0.3200 | train_accuracy: 0.8984 | test_accuracy: 0.8860\n",
      "[   46]/[  468] | train_loss: 0.3813 | train_accuracy: 0.8828 | test_accuracy: 0.8885\n",
      "[   47]/[  468] | train_loss: 0.3371 | train_accuracy: 0.8906 | test_accuracy: 0.8880\n",
      "[   48]/[  468] | train_loss: 0.3346 | train_accuracy: 0.9141 | test_accuracy: 0.8838\n",
      "[   49]/[  468] | train_loss: 0.5071 | train_accuracy: 0.8516 | test_accuracy: 0.8915\n",
      "[   50]/[  468] | train_loss: 0.3020 | train_accuracy: 0.9375 | test_accuracy: 0.8970\n",
      "[   51]/[  468] | train_loss: 0.3409 | train_accuracy: 0.9062 | test_accuracy: 0.9007\n",
      "[   52]/[  468] | train_loss: 0.3671 | train_accuracy: 0.9062 | test_accuracy: 0.9001\n",
      "[   53]/[  468] | train_loss: 0.4883 | train_accuracy: 0.8672 | test_accuracy: 0.8945\n",
      "[   54]/[  468] | train_loss: 0.5302 | train_accuracy: 0.8281 | test_accuracy: 0.8935\n",
      "[   55]/[  468] | train_loss: 0.4577 | train_accuracy: 0.8828 | test_accuracy: 0.9007\n",
      "[   56]/[  468] | train_loss: 0.3229 | train_accuracy: 0.9141 | test_accuracy: 0.9062\n",
      "[   57]/[  468] | train_loss: 0.2146 | train_accuracy: 0.9453 | test_accuracy: 0.9114\n",
      "[   58]/[  468] | train_loss: 0.2114 | train_accuracy: 0.9219 | test_accuracy: 0.9110\n",
      "[   59]/[  468] | train_loss: 0.2961 | train_accuracy: 0.9062 | test_accuracy: 0.9090\n",
      "[   60]/[  468] | train_loss: 0.3806 | train_accuracy: 0.8984 | test_accuracy: 0.9086\n",
      "[   61]/[  468] | train_loss: 0.2731 | train_accuracy: 0.8906 | test_accuracy: 0.9119\n",
      "[   62]/[  468] | train_loss: 0.2356 | train_accuracy: 0.9297 | test_accuracy: 0.9129\n",
      "[   63]/[  468] | train_loss: 0.2754 | train_accuracy: 0.9297 | test_accuracy: 0.9112\n",
      "[   64]/[  468] | train_loss: 0.2336 | train_accuracy: 0.9453 | test_accuracy: 0.9081\n",
      "[   65]/[  468] | train_loss: 0.2848 | train_accuracy: 0.9219 | test_accuracy: 0.9051\n",
      "[   66]/[  468] | train_loss: 0.4830 | train_accuracy: 0.8672 | test_accuracy: 0.9081\n",
      "[   67]/[  468] | train_loss: 0.2871 | train_accuracy: 0.9062 | test_accuracy: 0.9109\n",
      "[   68]/[  468] | train_loss: 0.2292 | train_accuracy: 0.9375 | test_accuracy: 0.9141\n",
      "[   69]/[  468] | train_loss: 0.3480 | train_accuracy: 0.8906 | test_accuracy: 0.9147\n",
      "[   70]/[  468] | train_loss: 0.2546 | train_accuracy: 0.9219 | test_accuracy: 0.9122\n",
      "[   71]/[  468] | train_loss: 0.3136 | train_accuracy: 0.9219 | test_accuracy: 0.9091\n",
      "[   72]/[  468] | train_loss: 0.3828 | train_accuracy: 0.8828 | test_accuracy: 0.9067\n",
      "[   73]/[  468] | train_loss: 0.3280 | train_accuracy: 0.9297 | test_accuracy: 0.9087\n",
      "[   74]/[  468] | train_loss: 0.1943 | train_accuracy: 0.9375 | test_accuracy: 0.9111\n",
      "[   75]/[  468] | train_loss: 0.3319 | train_accuracy: 0.8984 | test_accuracy: 0.9140\n",
      "[   76]/[  468] | train_loss: 0.3384 | train_accuracy: 0.8828 | test_accuracy: 0.9172\n",
      "[   77]/[  468] | train_loss: 0.2591 | train_accuracy: 0.8984 | test_accuracy: 0.9169\n",
      "[   78]/[  468] | train_loss: 0.2748 | train_accuracy: 0.9141 | test_accuracy: 0.9175\n",
      "[   79]/[  468] | train_loss: 0.4349 | train_accuracy: 0.8984 | test_accuracy: 0.9179\n",
      "[   80]/[  468] | train_loss: 0.3753 | train_accuracy: 0.8750 | test_accuracy: 0.9162\n",
      "[   81]/[  468] | train_loss: 0.1891 | train_accuracy: 0.9297 | test_accuracy: 0.9159\n",
      "[   82]/[  468] | train_loss: 0.2717 | train_accuracy: 0.8906 | test_accuracy: 0.9162\n",
      "[   83]/[  468] | train_loss: 0.2624 | train_accuracy: 0.9219 | test_accuracy: 0.9156\n",
      "[   84]/[  468] | train_loss: 0.3117 | train_accuracy: 0.8984 | test_accuracy: 0.9144\n",
      "[   85]/[  468] | train_loss: 0.2024 | train_accuracy: 0.9453 | test_accuracy: 0.9109\n",
      "[   86]/[  468] | train_loss: 0.2142 | train_accuracy: 0.9531 | test_accuracy: 0.9113\n",
      "[   87]/[  468] | train_loss: 0.3208 | train_accuracy: 0.9219 | test_accuracy: 0.9138\n",
      "[   88]/[  468] | train_loss: 0.2050 | train_accuracy: 0.9375 | test_accuracy: 0.9193\n",
      "[   89]/[  468] | train_loss: 0.3825 | train_accuracy: 0.8672 | test_accuracy: 0.9224\n",
      "[   90]/[  468] | train_loss: 0.2438 | train_accuracy: 0.9453 | test_accuracy: 0.9203\n",
      "[   91]/[  468] | train_loss: 0.2289 | train_accuracy: 0.9297 | test_accuracy: 0.9175\n",
      "[   92]/[  468] | train_loss: 0.4461 | train_accuracy: 0.8828 | test_accuracy: 0.9164\n",
      "[   93]/[  468] | train_loss: 0.3451 | train_accuracy: 0.9141 | test_accuracy: 0.9161\n",
      "[   94]/[  468] | train_loss: 0.3114 | train_accuracy: 0.9375 | test_accuracy: 0.9171\n",
      "[   95]/[  468] | train_loss: 0.1897 | train_accuracy: 0.9531 | test_accuracy: 0.9208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   96]/[  468] | train_loss: 0.1985 | train_accuracy: 0.9375 | test_accuracy: 0.9214\n",
      "[   97]/[  468] | train_loss: 0.1338 | train_accuracy: 0.9844 | test_accuracy: 0.9209\n",
      "[   98]/[  468] | train_loss: 0.1462 | train_accuracy: 0.9609 | test_accuracy: 0.9186\n",
      "[   99]/[  468] | train_loss: 0.2668 | train_accuracy: 0.9141 | test_accuracy: 0.9168\n",
      "[  100]/[  468] | train_loss: 0.2305 | train_accuracy: 0.9219 | test_accuracy: 0.9178\n",
      "[  101]/[  468] | train_loss: 0.1621 | train_accuracy: 0.9609 | test_accuracy: 0.9214\n",
      "[  102]/[  468] | train_loss: 0.2293 | train_accuracy: 0.9219 | test_accuracy: 0.9216\n",
      "[  103]/[  468] | train_loss: 0.1938 | train_accuracy: 0.9297 | test_accuracy: 0.9204\n",
      "[  104]/[  468] | train_loss: 0.1952 | train_accuracy: 0.9453 | test_accuracy: 0.9186\n",
      "[  105]/[  468] | train_loss: 0.3069 | train_accuracy: 0.9219 | test_accuracy: 0.9157\n",
      "[  106]/[  468] | train_loss: 0.2392 | train_accuracy: 0.9375 | test_accuracy: 0.9135\n",
      "[  107]/[  468] | train_loss: 0.2018 | train_accuracy: 0.9375 | test_accuracy: 0.9134\n",
      "[  108]/[  468] | train_loss: 0.2762 | train_accuracy: 0.9297 | test_accuracy: 0.9222\n",
      "[  109]/[  468] | train_loss: 0.3018 | train_accuracy: 0.9219 | test_accuracy: 0.9240\n",
      "[  110]/[  468] | train_loss: 0.1747 | train_accuracy: 0.9453 | test_accuracy: 0.9259\n",
      "[  111]/[  468] | train_loss: 0.2817 | train_accuracy: 0.9453 | test_accuracy: 0.9243\n",
      "[  112]/[  468] | train_loss: 0.1713 | train_accuracy: 0.9609 | test_accuracy: 0.9213\n",
      "[  113]/[  468] | train_loss: 0.2964 | train_accuracy: 0.9062 | test_accuracy: 0.9188\n",
      "[  114]/[  468] | train_loss: 0.2455 | train_accuracy: 0.9297 | test_accuracy: 0.9197\n",
      "[  115]/[  468] | train_loss: 0.1545 | train_accuracy: 0.9531 | test_accuracy: 0.9208\n",
      "[  116]/[  468] | train_loss: 0.3125 | train_accuracy: 0.9141 | test_accuracy: 0.9258\n",
      "[  117]/[  468] | train_loss: 0.3068 | train_accuracy: 0.9375 | test_accuracy: 0.9286\n",
      "[  118]/[  468] | train_loss: 0.3994 | train_accuracy: 0.8984 | test_accuracy: 0.9298\n",
      "[  119]/[  468] | train_loss: 0.1247 | train_accuracy: 0.9688 | test_accuracy: 0.9251\n",
      "[  120]/[  468] | train_loss: 0.2275 | train_accuracy: 0.9141 | test_accuracy: 0.9230\n",
      "[  121]/[  468] | train_loss: 0.2583 | train_accuracy: 0.9141 | test_accuracy: 0.9252\n",
      "[  122]/[  468] | train_loss: 0.1959 | train_accuracy: 0.9141 | test_accuracy: 0.9253\n",
      "[  123]/[  468] | train_loss: 0.2879 | train_accuracy: 0.9375 | test_accuracy: 0.9295\n",
      "[  124]/[  468] | train_loss: 0.2805 | train_accuracy: 0.9297 | test_accuracy: 0.9321\n",
      "[  125]/[  468] | train_loss: 0.2155 | train_accuracy: 0.9453 | test_accuracy: 0.9336\n",
      "[  126]/[  468] | train_loss: 0.1162 | train_accuracy: 0.9688 | test_accuracy: 0.9322\n",
      "[  127]/[  468] | train_loss: 0.3462 | train_accuracy: 0.9141 | test_accuracy: 0.9317\n",
      "[  128]/[  468] | train_loss: 0.1840 | train_accuracy: 0.9688 | test_accuracy: 0.9335\n",
      "[  129]/[  468] | train_loss: 0.1771 | train_accuracy: 0.9375 | test_accuracy: 0.9339\n",
      "[  130]/[  468] | train_loss: 0.1647 | train_accuracy: 0.9609 | test_accuracy: 0.9337\n",
      "[  131]/[  468] | train_loss: 0.1808 | train_accuracy: 0.9453 | test_accuracy: 0.9336\n",
      "[  132]/[  468] | train_loss: 0.1383 | train_accuracy: 0.9531 | test_accuracy: 0.9343\n",
      "[  133]/[  468] | train_loss: 0.2311 | train_accuracy: 0.9453 | test_accuracy: 0.9332\n",
      "[  134]/[  468] | train_loss: 0.3154 | train_accuracy: 0.9297 | test_accuracy: 0.9303\n",
      "[  135]/[  468] | train_loss: 0.2319 | train_accuracy: 0.9141 | test_accuracy: 0.9266\n",
      "[  136]/[  468] | train_loss: 0.2641 | train_accuracy: 0.9141 | test_accuracy: 0.9236\n",
      "[  137]/[  468] | train_loss: 0.3157 | train_accuracy: 0.9141 | test_accuracy: 0.9213\n",
      "[  138]/[  468] | train_loss: 0.3543 | train_accuracy: 0.8906 | test_accuracy: 0.9240\n",
      "[  139]/[  468] | train_loss: 0.2378 | train_accuracy: 0.9219 | test_accuracy: 0.9290\n",
      "[  140]/[  468] | train_loss: 0.2194 | train_accuracy: 0.9531 | test_accuracy: 0.9318\n",
      "[  141]/[  468] | train_loss: 0.3389 | train_accuracy: 0.9219 | test_accuracy: 0.9324\n",
      "[  142]/[  468] | train_loss: 0.2712 | train_accuracy: 0.9062 | test_accuracy: 0.9321\n",
      "[  143]/[  468] | train_loss: 0.1359 | train_accuracy: 0.9688 | test_accuracy: 0.9301\n",
      "[  144]/[  468] | train_loss: 0.1659 | train_accuracy: 0.9609 | test_accuracy: 0.9291\n",
      "[  145]/[  468] | train_loss: 0.2829 | train_accuracy: 0.9062 | test_accuracy: 0.9276\n",
      "[  146]/[  468] | train_loss: 0.2943 | train_accuracy: 0.9219 | test_accuracy: 0.9302\n",
      "[  147]/[  468] | train_loss: 0.2450 | train_accuracy: 0.9062 | test_accuracy: 0.9357\n",
      "[  148]/[  468] | train_loss: 0.2097 | train_accuracy: 0.9453 | test_accuracy: 0.9380\n",
      "[  149]/[  468] | train_loss: 0.2483 | train_accuracy: 0.9141 | test_accuracy: 0.9383\n",
      "[  150]/[  468] | train_loss: 0.2416 | train_accuracy: 0.9453 | test_accuracy: 0.9375\n",
      "[  151]/[  468] | train_loss: 0.2521 | train_accuracy: 0.9219 | test_accuracy: 0.9353\n",
      "[  152]/[  468] | train_loss: 0.1598 | train_accuracy: 0.9531 | test_accuracy: 0.9341\n",
      "[  153]/[  468] | train_loss: 0.2426 | train_accuracy: 0.9219 | test_accuracy: 0.9352\n",
      "[  154]/[  468] | train_loss: 0.2157 | train_accuracy: 0.9297 | test_accuracy: 0.9361\n",
      "[  155]/[  468] | train_loss: 0.2641 | train_accuracy: 0.8906 | test_accuracy: 0.9357\n",
      "[  156]/[  468] | train_loss: 0.2695 | train_accuracy: 0.9219 | test_accuracy: 0.9375\n",
      "[  157]/[  468] | train_loss: 0.3205 | train_accuracy: 0.9141 | test_accuracy: 0.9374\n",
      "[  158]/[  468] | train_loss: 0.1922 | train_accuracy: 0.9453 | test_accuracy: 0.9342\n",
      "[  159]/[  468] | train_loss: 0.2113 | train_accuracy: 0.9219 | test_accuracy: 0.9327\n",
      "[  160]/[  468] | train_loss: 0.2842 | train_accuracy: 0.9219 | test_accuracy: 0.9299\n",
      "[  161]/[  468] | train_loss: 0.2256 | train_accuracy: 0.9297 | test_accuracy: 0.9314\n",
      "[  162]/[  468] | train_loss: 0.2141 | train_accuracy: 0.9375 | test_accuracy: 0.9347\n",
      "[  163]/[  468] | train_loss: 0.2297 | train_accuracy: 0.9062 | test_accuracy: 0.9388\n",
      "[  164]/[  468] | train_loss: 0.1891 | train_accuracy: 0.9375 | test_accuracy: 0.9392\n",
      "[  165]/[  468] | train_loss: 0.2070 | train_accuracy: 0.9531 | test_accuracy: 0.9378\n",
      "[  166]/[  468] | train_loss: 0.1939 | train_accuracy: 0.9531 | test_accuracy: 0.9358\n",
      "[  167]/[  468] | train_loss: 0.1306 | train_accuracy: 0.9531 | test_accuracy: 0.9326\n",
      "[  168]/[  468] | train_loss: 0.2400 | train_accuracy: 0.9531 | test_accuracy: 0.9308\n",
      "[  169]/[  468] | train_loss: 0.2255 | train_accuracy: 0.9297 | test_accuracy: 0.9316\n",
      "[  170]/[  468] | train_loss: 0.1810 | train_accuracy: 0.9375 | test_accuracy: 0.9329\n",
      "[  171]/[  468] | train_loss: 0.2772 | train_accuracy: 0.9062 | test_accuracy: 0.9336\n",
      "[  172]/[  468] | train_loss: 0.2255 | train_accuracy: 0.9375 | test_accuracy: 0.9338\n",
      "[  173]/[  468] | train_loss: 0.3313 | train_accuracy: 0.9141 | test_accuracy: 0.9326\n",
      "[  174]/[  468] | train_loss: 0.2780 | train_accuracy: 0.9375 | test_accuracy: 0.9315\n",
      "[  175]/[  468] | train_loss: 0.2210 | train_accuracy: 0.9297 | test_accuracy: 0.9328\n",
      "[  176]/[  468] | train_loss: 0.2271 | train_accuracy: 0.9375 | test_accuracy: 0.9338\n",
      "[  177]/[  468] | train_loss: 0.1062 | train_accuracy: 0.9688 | test_accuracy: 0.9359\n",
      "[  178]/[  468] | train_loss: 0.3498 | train_accuracy: 0.8516 | test_accuracy: 0.9389\n",
      "[  179]/[  468] | train_loss: 0.2760 | train_accuracy: 0.9219 | test_accuracy: 0.9388\n",
      "[  180]/[  468] | train_loss: 0.2511 | train_accuracy: 0.9609 | test_accuracy: 0.9376\n",
      "[  181]/[  468] | train_loss: 0.1996 | train_accuracy: 0.9453 | test_accuracy: 0.9343\n",
      "[  182]/[  468] | train_loss: 0.1839 | train_accuracy: 0.9453 | test_accuracy: 0.9307\n",
      "[  183]/[  468] | train_loss: 0.2608 | train_accuracy: 0.9219 | test_accuracy: 0.9331\n",
      "[  184]/[  468] | train_loss: 0.1512 | train_accuracy: 0.9453 | test_accuracy: 0.9327\n",
      "[  185]/[  468] | train_loss: 0.1514 | train_accuracy: 0.9609 | test_accuracy: 0.9352\n",
      "[  186]/[  468] | train_loss: 0.1572 | train_accuracy: 0.9688 | test_accuracy: 0.9370\n",
      "[  187]/[  468] | train_loss: 0.0967 | train_accuracy: 0.9688 | test_accuracy: 0.9390\n",
      "[  188]/[  468] | train_loss: 0.1630 | train_accuracy: 0.9375 | test_accuracy: 0.9402\n",
      "[  189]/[  468] | train_loss: 0.1518 | train_accuracy: 0.9375 | test_accuracy: 0.9397\n",
      "[  190]/[  468] | train_loss: 0.3233 | train_accuracy: 0.9219 | test_accuracy: 0.9397\n",
      "[  191]/[  468] | train_loss: 0.1458 | train_accuracy: 0.9766 | test_accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  192]/[  468] | train_loss: 0.1841 | train_accuracy: 0.9609 | test_accuracy: 0.9365\n",
      "[  193]/[  468] | train_loss: 0.1927 | train_accuracy: 0.9375 | test_accuracy: 0.9368\n",
      "[  194]/[  468] | train_loss: 0.2615 | train_accuracy: 0.9062 | test_accuracy: 0.9393\n",
      "[  195]/[  468] | train_loss: 0.0828 | train_accuracy: 0.9844 | test_accuracy: 0.9403\n",
      "[  196]/[  468] | train_loss: 0.2031 | train_accuracy: 0.9297 | test_accuracy: 0.9419\n",
      "[  197]/[  468] | train_loss: 0.1621 | train_accuracy: 0.9688 | test_accuracy: 0.9435\n",
      "[  198]/[  468] | train_loss: 0.2155 | train_accuracy: 0.9375 | test_accuracy: 0.9443\n",
      "[  199]/[  468] | train_loss: 0.3267 | train_accuracy: 0.8906 | test_accuracy: 0.9452\n",
      "[  200]/[  468] | train_loss: 0.1910 | train_accuracy: 0.9297 | test_accuracy: 0.9467\n",
      "[  201]/[  468] | train_loss: 0.2309 | train_accuracy: 0.9453 | test_accuracy: 0.9461\n",
      "[  202]/[  468] | train_loss: 0.2110 | train_accuracy: 0.9375 | test_accuracy: 0.9449\n",
      "[  203]/[  468] | train_loss: 0.1075 | train_accuracy: 0.9766 | test_accuracy: 0.9435\n",
      "[  204]/[  468] | train_loss: 0.1642 | train_accuracy: 0.9531 | test_accuracy: 0.9410\n",
      "[  205]/[  468] | train_loss: 0.2089 | train_accuracy: 0.9453 | test_accuracy: 0.9417\n",
      "[  206]/[  468] | train_loss: 0.1772 | train_accuracy: 0.9609 | test_accuracy: 0.9433\n",
      "[  207]/[  468] | train_loss: 0.2272 | train_accuracy: 0.9375 | test_accuracy: 0.9458\n",
      "[  208]/[  468] | train_loss: 0.1487 | train_accuracy: 0.9609 | test_accuracy: 0.9471\n",
      "[  209]/[  468] | train_loss: 0.2077 | train_accuracy: 0.9219 | test_accuracy: 0.9463\n",
      "[  210]/[  468] | train_loss: 0.1827 | train_accuracy: 0.9531 | test_accuracy: 0.9469\n",
      "[  211]/[  468] | train_loss: 0.3131 | train_accuracy: 0.8906 | test_accuracy: 0.9473\n",
      "[  212]/[  468] | train_loss: 0.0871 | train_accuracy: 0.9766 | test_accuracy: 0.9474\n",
      "[  213]/[  468] | train_loss: 0.1375 | train_accuracy: 0.9688 | test_accuracy: 0.9470\n",
      "[  214]/[  468] | train_loss: 0.1701 | train_accuracy: 0.9375 | test_accuracy: 0.9469\n",
      "[  215]/[  468] | train_loss: 0.1315 | train_accuracy: 0.9531 | test_accuracy: 0.9475\n",
      "[  216]/[  468] | train_loss: 0.1373 | train_accuracy: 0.9531 | test_accuracy: 0.9478\n",
      "[  217]/[  468] | train_loss: 0.1177 | train_accuracy: 0.9688 | test_accuracy: 0.9464\n",
      "[  218]/[  468] | train_loss: 0.1309 | train_accuracy: 0.9609 | test_accuracy: 0.9455\n",
      "[  219]/[  468] | train_loss: 0.1433 | train_accuracy: 0.9531 | test_accuracy: 0.9438\n",
      "[  220]/[  468] | train_loss: 0.1720 | train_accuracy: 0.9297 | test_accuracy: 0.9437\n",
      "[  221]/[  468] | train_loss: 0.2245 | train_accuracy: 0.9062 | test_accuracy: 0.9457\n",
      "[  222]/[  468] | train_loss: 0.0713 | train_accuracy: 0.9844 | test_accuracy: 0.9469\n",
      "[  223]/[  468] | train_loss: 0.1117 | train_accuracy: 0.9609 | test_accuracy: 0.9483\n",
      "[  224]/[  468] | train_loss: 0.2035 | train_accuracy: 0.9375 | test_accuracy: 0.9491\n",
      "[  225]/[  468] | train_loss: 0.1542 | train_accuracy: 0.9766 | test_accuracy: 0.9491\n",
      "[  226]/[  468] | train_loss: 0.1470 | train_accuracy: 0.9609 | test_accuracy: 0.9475\n",
      "[  227]/[  468] | train_loss: 0.2549 | train_accuracy: 0.9375 | test_accuracy: 0.9476\n",
      "[  228]/[  468] | train_loss: 0.1399 | train_accuracy: 0.9375 | test_accuracy: 0.9473\n",
      "[  229]/[  468] | train_loss: 0.1325 | train_accuracy: 0.9609 | test_accuracy: 0.9451\n",
      "[  230]/[  468] | train_loss: 0.2159 | train_accuracy: 0.9531 | test_accuracy: 0.9447\n",
      "[  231]/[  468] | train_loss: 0.1891 | train_accuracy: 0.9531 | test_accuracy: 0.9465\n",
      "[  232]/[  468] | train_loss: 0.1553 | train_accuracy: 0.9531 | test_accuracy: 0.9482\n",
      "[  233]/[  468] | train_loss: 0.2094 | train_accuracy: 0.9375 | test_accuracy: 0.9478\n",
      "[  234]/[  468] | train_loss: 0.0627 | train_accuracy: 0.9844 | test_accuracy: 0.9480\n",
      "[  235]/[  468] | train_loss: 0.0932 | train_accuracy: 0.9609 | test_accuracy: 0.9475\n",
      "[  236]/[  468] | train_loss: 0.1879 | train_accuracy: 0.9453 | test_accuracy: 0.9482\n",
      "[  237]/[  468] | train_loss: 0.1334 | train_accuracy: 0.9531 | test_accuracy: 0.9485\n",
      "[  238]/[  468] | train_loss: 0.2077 | train_accuracy: 0.9219 | test_accuracy: 0.9494\n",
      "[  239]/[  468] | train_loss: 0.0788 | train_accuracy: 0.9766 | test_accuracy: 0.9493\n",
      "[  240]/[  468] | train_loss: 0.1688 | train_accuracy: 0.9219 | test_accuracy: 0.9490\n",
      "[  241]/[  468] | train_loss: 0.0711 | train_accuracy: 0.9766 | test_accuracy: 0.9476\n",
      "[  242]/[  468] | train_loss: 0.2427 | train_accuracy: 0.9375 | test_accuracy: 0.9470\n",
      "[  243]/[  468] | train_loss: 0.2356 | train_accuracy: 0.9297 | test_accuracy: 0.9482\n",
      "[  244]/[  468] | train_loss: 0.1480 | train_accuracy: 0.9688 | test_accuracy: 0.9498\n",
      "[  245]/[  468] | train_loss: 0.1250 | train_accuracy: 0.9609 | test_accuracy: 0.9489\n",
      "[  246]/[  468] | train_loss: 0.2311 | train_accuracy: 0.9219 | test_accuracy: 0.9477\n",
      "[  247]/[  468] | train_loss: 0.1462 | train_accuracy: 0.9375 | test_accuracy: 0.9476\n",
      "[  248]/[  468] | train_loss: 0.1351 | train_accuracy: 0.9609 | test_accuracy: 0.9486\n",
      "[  249]/[  468] | train_loss: 0.1641 | train_accuracy: 0.9531 | test_accuracy: 0.9483\n",
      "[  250]/[  468] | train_loss: 0.1167 | train_accuracy: 0.9609 | test_accuracy: 0.9478\n",
      "[  251]/[  468] | train_loss: 0.2459 | train_accuracy: 0.9375 | test_accuracy: 0.9488\n",
      "[  252]/[  468] | train_loss: 0.1742 | train_accuracy: 0.9453 | test_accuracy: 0.9497\n",
      "[  253]/[  468] | train_loss: 0.1140 | train_accuracy: 0.9688 | test_accuracy: 0.9507\n",
      "[  254]/[  468] | train_loss: 0.1142 | train_accuracy: 0.9688 | test_accuracy: 0.9475\n",
      "[  255]/[  468] | train_loss: 0.0860 | train_accuracy: 0.9766 | test_accuracy: 0.9444\n",
      "[  256]/[  468] | train_loss: 0.1670 | train_accuracy: 0.9609 | test_accuracy: 0.9430\n",
      "[  257]/[  468] | train_loss: 0.1546 | train_accuracy: 0.9531 | test_accuracy: 0.9435\n",
      "[  258]/[  468] | train_loss: 0.2046 | train_accuracy: 0.9453 | test_accuracy: 0.9436\n",
      "[  259]/[  468] | train_loss: 0.1631 | train_accuracy: 0.9531 | test_accuracy: 0.9438\n",
      "[  260]/[  468] | train_loss: 0.1858 | train_accuracy: 0.9453 | test_accuracy: 0.9439\n",
      "[  261]/[  468] | train_loss: 0.1295 | train_accuracy: 0.9688 | test_accuracy: 0.9467\n",
      "[  262]/[  468] | train_loss: 0.1481 | train_accuracy: 0.9531 | test_accuracy: 0.9475\n",
      "[  263]/[  468] | train_loss: 0.1010 | train_accuracy: 0.9688 | test_accuracy: 0.9480\n",
      "[  264]/[  468] | train_loss: 0.1594 | train_accuracy: 0.9531 | test_accuracy: 0.9493\n",
      "[  265]/[  468] | train_loss: 0.2933 | train_accuracy: 0.9141 | test_accuracy: 0.9503\n",
      "[  266]/[  468] | train_loss: 0.2193 | train_accuracy: 0.9375 | test_accuracy: 0.9497\n",
      "[  267]/[  468] | train_loss: 0.1576 | train_accuracy: 0.9531 | test_accuracy: 0.9480\n",
      "[  268]/[  468] | train_loss: 0.1512 | train_accuracy: 0.9531 | test_accuracy: 0.9475\n",
      "[  269]/[  468] | train_loss: 0.1246 | train_accuracy: 0.9609 | test_accuracy: 0.9454\n",
      "[  270]/[  468] | train_loss: 0.1547 | train_accuracy: 0.9531 | test_accuracy: 0.9468\n",
      "[  271]/[  468] | train_loss: 0.2041 | train_accuracy: 0.9531 | test_accuracy: 0.9511\n",
      "[  272]/[  468] | train_loss: 0.1039 | train_accuracy: 0.9609 | test_accuracy: 0.9515\n",
      "[  273]/[  468] | train_loss: 0.1912 | train_accuracy: 0.9453 | test_accuracy: 0.9512\n",
      "[  274]/[  468] | train_loss: 0.1558 | train_accuracy: 0.9609 | test_accuracy: 0.9514\n",
      "[  275]/[  468] | train_loss: 0.1244 | train_accuracy: 0.9609 | test_accuracy: 0.9520\n",
      "[  276]/[  468] | train_loss: 0.1271 | train_accuracy: 0.9688 | test_accuracy: 0.9509\n",
      "[  277]/[  468] | train_loss: 0.1369 | train_accuracy: 0.9688 | test_accuracy: 0.9502\n",
      "[  278]/[  468] | train_loss: 0.1064 | train_accuracy: 0.9844 | test_accuracy: 0.9495\n",
      "[  279]/[  468] | train_loss: 0.1647 | train_accuracy: 0.9531 | test_accuracy: 0.9499\n",
      "[  280]/[  468] | train_loss: 0.1483 | train_accuracy: 0.9453 | test_accuracy: 0.9503\n",
      "[  281]/[  468] | train_loss: 0.1796 | train_accuracy: 0.9375 | test_accuracy: 0.9527\n",
      "[  282]/[  468] | train_loss: 0.1260 | train_accuracy: 0.9766 | test_accuracy: 0.9533\n",
      "[  283]/[  468] | train_loss: 0.1206 | train_accuracy: 0.9688 | test_accuracy: 0.9523\n",
      "[  284]/[  468] | train_loss: 0.1392 | train_accuracy: 0.9531 | test_accuracy: 0.9505\n",
      "[  285]/[  468] | train_loss: 0.1563 | train_accuracy: 0.9609 | test_accuracy: 0.9500\n",
      "[  286]/[  468] | train_loss: 0.1873 | train_accuracy: 0.9609 | test_accuracy: 0.9501\n",
      "[  287]/[  468] | train_loss: 0.1508 | train_accuracy: 0.9609 | test_accuracy: 0.9514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  288]/[  468] | train_loss: 0.1913 | train_accuracy: 0.9219 | test_accuracy: 0.9537\n",
      "[  289]/[  468] | train_loss: 0.1781 | train_accuracy: 0.9609 | test_accuracy: 0.9551\n",
      "[  290]/[  468] | train_loss: 0.1791 | train_accuracy: 0.9297 | test_accuracy: 0.9524\n",
      "[  291]/[  468] | train_loss: 0.0866 | train_accuracy: 0.9531 | test_accuracy: 0.9471\n",
      "[  292]/[  468] | train_loss: 0.2196 | train_accuracy: 0.9297 | test_accuracy: 0.9429\n",
      "[  293]/[  468] | train_loss: 0.0751 | train_accuracy: 0.9766 | test_accuracy: 0.9403\n",
      "[  294]/[  468] | train_loss: 0.1792 | train_accuracy: 0.9453 | test_accuracy: 0.9398\n",
      "[  295]/[  468] | train_loss: 0.2022 | train_accuracy: 0.9297 | test_accuracy: 0.9440\n",
      "[  296]/[  468] | train_loss: 0.1500 | train_accuracy: 0.9453 | test_accuracy: 0.9472\n",
      "[  297]/[  468] | train_loss: 0.1718 | train_accuracy: 0.9453 | test_accuracy: 0.9505\n",
      "[  298]/[  468] | train_loss: 0.1283 | train_accuracy: 0.9766 | test_accuracy: 0.9515\n",
      "[  299]/[  468] | train_loss: 0.0874 | train_accuracy: 0.9844 | test_accuracy: 0.9493\n",
      "[  300]/[  468] | train_loss: 0.1105 | train_accuracy: 0.9609 | test_accuracy: 0.9502\n",
      "[  301]/[  468] | train_loss: 0.1655 | train_accuracy: 0.9531 | test_accuracy: 0.9496\n",
      "[  302]/[  468] | train_loss: 0.1973 | train_accuracy: 0.9609 | test_accuracy: 0.9487\n",
      "[  303]/[  468] | train_loss: 0.1894 | train_accuracy: 0.9219 | test_accuracy: 0.9487\n",
      "[  304]/[  468] | train_loss: 0.1214 | train_accuracy: 0.9609 | test_accuracy: 0.9478\n",
      "[  305]/[  468] | train_loss: 0.1502 | train_accuracy: 0.9453 | test_accuracy: 0.9478\n",
      "[  306]/[  468] | train_loss: 0.1926 | train_accuracy: 0.9688 | test_accuracy: 0.9495\n",
      "[  307]/[  468] | train_loss: 0.1333 | train_accuracy: 0.9375 | test_accuracy: 0.9500\n",
      "[  308]/[  468] | train_loss: 0.0886 | train_accuracy: 0.9766 | test_accuracy: 0.9495\n",
      "[  309]/[  468] | train_loss: 0.1295 | train_accuracy: 0.9688 | test_accuracy: 0.9492\n",
      "[  310]/[  468] | train_loss: 0.3233 | train_accuracy: 0.9219 | test_accuracy: 0.9504\n",
      "[  311]/[  468] | train_loss: 0.2146 | train_accuracy: 0.9219 | test_accuracy: 0.9519\n",
      "[  312]/[  468] | train_loss: 0.2535 | train_accuracy: 0.9141 | test_accuracy: 0.9532\n",
      "[  313]/[  468] | train_loss: 0.0951 | train_accuracy: 0.9609 | test_accuracy: 0.9539\n",
      "[  314]/[  468] | train_loss: 0.2078 | train_accuracy: 0.9219 | test_accuracy: 0.9545\n",
      "[  315]/[  468] | train_loss: 0.0825 | train_accuracy: 0.9844 | test_accuracy: 0.9544\n",
      "[  316]/[  468] | train_loss: 0.2410 | train_accuracy: 0.9297 | test_accuracy: 0.9531\n",
      "[  317]/[  468] | train_loss: 0.1716 | train_accuracy: 0.9453 | test_accuracy: 0.9531\n",
      "[  318]/[  468] | train_loss: 0.2378 | train_accuracy: 0.9453 | test_accuracy: 0.9545\n",
      "[  319]/[  468] | train_loss: 0.0967 | train_accuracy: 0.9688 | test_accuracy: 0.9541\n",
      "[  320]/[  468] | train_loss: 0.1319 | train_accuracy: 0.9531 | test_accuracy: 0.9530\n",
      "[  321]/[  468] | train_loss: 0.1953 | train_accuracy: 0.9453 | test_accuracy: 0.9530\n",
      "[  322]/[  468] | train_loss: 0.1198 | train_accuracy: 0.9688 | test_accuracy: 0.9512\n",
      "[  323]/[  468] | train_loss: 0.1471 | train_accuracy: 0.9375 | test_accuracy: 0.9509\n",
      "[  324]/[  468] | train_loss: 0.1455 | train_accuracy: 0.9453 | test_accuracy: 0.9511\n",
      "[  325]/[  468] | train_loss: 0.2283 | train_accuracy: 0.9375 | test_accuracy: 0.9506\n",
      "[  326]/[  468] | train_loss: 0.1054 | train_accuracy: 0.9609 | test_accuracy: 0.9513\n",
      "[  327]/[  468] | train_loss: 0.1049 | train_accuracy: 0.9531 | test_accuracy: 0.9533\n",
      "[  328]/[  468] | train_loss: 0.0807 | train_accuracy: 0.9844 | test_accuracy: 0.9560\n",
      "[  329]/[  468] | train_loss: 0.1604 | train_accuracy: 0.9609 | test_accuracy: 0.9558\n",
      "[  330]/[  468] | train_loss: 0.1359 | train_accuracy: 0.9688 | test_accuracy: 0.9567\n",
      "[  331]/[  468] | train_loss: 0.1409 | train_accuracy: 0.9609 | test_accuracy: 0.9574\n",
      "[  332]/[  468] | train_loss: 0.0901 | train_accuracy: 0.9688 | test_accuracy: 0.9562\n",
      "[  333]/[  468] | train_loss: 0.0787 | train_accuracy: 0.9688 | test_accuracy: 0.9543\n",
      "[  334]/[  468] | train_loss: 0.1961 | train_accuracy: 0.9609 | test_accuracy: 0.9541\n",
      "[  335]/[  468] | train_loss: 0.1698 | train_accuracy: 0.9531 | test_accuracy: 0.9551\n",
      "[  336]/[  468] | train_loss: 0.1090 | train_accuracy: 0.9609 | test_accuracy: 0.9559\n",
      "[  337]/[  468] | train_loss: 0.0551 | train_accuracy: 1.0000 | test_accuracy: 0.9560\n",
      "[  338]/[  468] | train_loss: 0.1752 | train_accuracy: 0.9531 | test_accuracy: 0.9557\n",
      "[  339]/[  468] | train_loss: 0.2539 | train_accuracy: 0.9297 | test_accuracy: 0.9571\n",
      "[  340]/[  468] | train_loss: 0.2050 | train_accuracy: 0.9531 | test_accuracy: 0.9578\n",
      "[  341]/[  468] | train_loss: 0.2786 | train_accuracy: 0.9375 | test_accuracy: 0.9567\n",
      "[  342]/[  468] | train_loss: 0.1542 | train_accuracy: 0.9609 | test_accuracy: 0.9552\n",
      "[  343]/[  468] | train_loss: 0.0630 | train_accuracy: 0.9922 | test_accuracy: 0.9543\n",
      "[  344]/[  468] | train_loss: 0.1006 | train_accuracy: 0.9531 | test_accuracy: 0.9558\n",
      "[  345]/[  468] | train_loss: 0.1096 | train_accuracy: 0.9766 | test_accuracy: 0.9580\n",
      "[  346]/[  468] | train_loss: 0.1275 | train_accuracy: 0.9688 | test_accuracy: 0.9580\n",
      "[  347]/[  468] | train_loss: 0.1873 | train_accuracy: 0.9531 | test_accuracy: 0.9583\n",
      "[  348]/[  468] | train_loss: 0.1578 | train_accuracy: 0.9375 | test_accuracy: 0.9589\n",
      "[  349]/[  468] | train_loss: 0.2149 | train_accuracy: 0.9609 | test_accuracy: 0.9587\n",
      "[  350]/[  468] | train_loss: 0.1391 | train_accuracy: 0.9531 | test_accuracy: 0.9591\n",
      "[  351]/[  468] | train_loss: 0.1124 | train_accuracy: 0.9688 | test_accuracy: 0.9579\n",
      "[  352]/[  468] | train_loss: 0.1233 | train_accuracy: 0.9609 | test_accuracy: 0.9581\n",
      "[  353]/[  468] | train_loss: 0.0808 | train_accuracy: 0.9688 | test_accuracy: 0.9583\n",
      "[  354]/[  468] | train_loss: 0.1314 | train_accuracy: 0.9844 | test_accuracy: 0.9578\n",
      "[  355]/[  468] | train_loss: 0.2492 | train_accuracy: 0.9609 | test_accuracy: 0.9590\n",
      "[  356]/[  468] | train_loss: 0.0812 | train_accuracy: 0.9844 | test_accuracy: 0.9594\n",
      "[  357]/[  468] | train_loss: 0.1222 | train_accuracy: 0.9531 | test_accuracy: 0.9604\n",
      "[  358]/[  468] | train_loss: 0.0755 | train_accuracy: 0.9766 | test_accuracy: 0.9592\n",
      "[  359]/[  468] | train_loss: 0.1582 | train_accuracy: 0.9609 | test_accuracy: 0.9596\n",
      "[  360]/[  468] | train_loss: 0.0849 | train_accuracy: 0.9688 | test_accuracy: 0.9589\n",
      "[  361]/[  468] | train_loss: 0.1730 | train_accuracy: 0.9453 | test_accuracy: 0.9590\n",
      "[  362]/[  468] | train_loss: 0.1045 | train_accuracy: 0.9766 | test_accuracy: 0.9589\n",
      "[  363]/[  468] | train_loss: 0.1303 | train_accuracy: 0.9688 | test_accuracy: 0.9587\n",
      "[  364]/[  468] | train_loss: 0.2489 | train_accuracy: 0.9375 | test_accuracy: 0.9606\n",
      "[  365]/[  468] | train_loss: 0.1713 | train_accuracy: 0.9375 | test_accuracy: 0.9604\n",
      "[  366]/[  468] | train_loss: 0.1188 | train_accuracy: 0.9688 | test_accuracy: 0.9603\n",
      "[  367]/[  468] | train_loss: 0.1590 | train_accuracy: 0.9766 | test_accuracy: 0.9588\n",
      "[  368]/[  468] | train_loss: 0.1500 | train_accuracy: 0.9688 | test_accuracy: 0.9575\n",
      "[  369]/[  468] | train_loss: 0.1793 | train_accuracy: 0.9609 | test_accuracy: 0.9549\n",
      "[  370]/[  468] | train_loss: 0.1736 | train_accuracy: 0.9609 | test_accuracy: 0.9549\n",
      "[  371]/[  468] | train_loss: 0.1274 | train_accuracy: 0.9453 | test_accuracy: 0.9556\n",
      "[  372]/[  468] | train_loss: 0.1560 | train_accuracy: 0.9453 | test_accuracy: 0.9579\n",
      "[  373]/[  468] | train_loss: 0.1292 | train_accuracy: 0.9609 | test_accuracy: 0.9588\n",
      "[  374]/[  468] | train_loss: 0.0878 | train_accuracy: 0.9766 | test_accuracy: 0.9597\n",
      "[  375]/[  468] | train_loss: 0.1646 | train_accuracy: 0.9453 | test_accuracy: 0.9605\n",
      "[  376]/[  468] | train_loss: 0.0999 | train_accuracy: 0.9766 | test_accuracy: 0.9604\n",
      "[  377]/[  468] | train_loss: 0.1117 | train_accuracy: 0.9688 | test_accuracy: 0.9591\n",
      "[  378]/[  468] | train_loss: 0.2051 | train_accuracy: 0.9609 | test_accuracy: 0.9574\n",
      "[  379]/[  468] | train_loss: 0.1002 | train_accuracy: 0.9531 | test_accuracy: 0.9572\n",
      "[  380]/[  468] | train_loss: 0.1687 | train_accuracy: 0.9219 | test_accuracy: 0.9574\n",
      "[  381]/[  468] | train_loss: 0.1081 | train_accuracy: 0.9609 | test_accuracy: 0.9572\n",
      "[  382]/[  468] | train_loss: 0.1272 | train_accuracy: 0.9609 | test_accuracy: 0.9587\n",
      "[  383]/[  468] | train_loss: 0.1577 | train_accuracy: 0.9531 | test_accuracy: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  384]/[  468] | train_loss: 0.0853 | train_accuracy: 0.9688 | test_accuracy: 0.9598\n",
      "[  385]/[  468] | train_loss: 0.0542 | train_accuracy: 0.9922 | test_accuracy: 0.9589\n",
      "[  386]/[  468] | train_loss: 0.1344 | train_accuracy: 0.9766 | test_accuracy: 0.9595\n",
      "[  387]/[  468] | train_loss: 0.0553 | train_accuracy: 0.9922 | test_accuracy: 0.9579\n",
      "[  388]/[  468] | train_loss: 0.1348 | train_accuracy: 0.9609 | test_accuracy: 0.9554\n",
      "[  389]/[  468] | train_loss: 0.2329 | train_accuracy: 0.9297 | test_accuracy: 0.9541\n",
      "[  390]/[  468] | train_loss: 0.1598 | train_accuracy: 0.9844 | test_accuracy: 0.9540\n",
      "[  391]/[  468] | train_loss: 0.1533 | train_accuracy: 0.9766 | test_accuracy: 0.9548\n",
      "[  392]/[  468] | train_loss: 0.1032 | train_accuracy: 0.9688 | test_accuracy: 0.9558\n",
      "[  393]/[  468] | train_loss: 0.1559 | train_accuracy: 0.9609 | test_accuracy: 0.9571\n",
      "[  394]/[  468] | train_loss: 0.1486 | train_accuracy: 0.9766 | test_accuracy: 0.9578\n",
      "[  395]/[  468] | train_loss: 0.1938 | train_accuracy: 0.9531 | test_accuracy: 0.9581\n",
      "[  396]/[  468] | train_loss: 0.0808 | train_accuracy: 0.9844 | test_accuracy: 0.9574\n",
      "[  397]/[  468] | train_loss: 0.1020 | train_accuracy: 0.9766 | test_accuracy: 0.9554\n",
      "[  398]/[  468] | train_loss: 0.1924 | train_accuracy: 0.9453 | test_accuracy: 0.9535\n",
      "[  399]/[  468] | train_loss: 0.1446 | train_accuracy: 0.9688 | test_accuracy: 0.9526\n",
      "[  400]/[  468] | train_loss: 0.1557 | train_accuracy: 0.9531 | test_accuracy: 0.9556\n",
      "[  401]/[  468] | train_loss: 0.1005 | train_accuracy: 0.9766 | test_accuracy: 0.9566\n",
      "[  402]/[  468] | train_loss: 0.0721 | train_accuracy: 0.9844 | test_accuracy: 0.9579\n",
      "[  403]/[  468] | train_loss: 0.1145 | train_accuracy: 0.9609 | test_accuracy: 0.9582\n",
      "[  404]/[  468] | train_loss: 0.1606 | train_accuracy: 0.9375 | test_accuracy: 0.9600\n",
      "[  405]/[  468] | train_loss: 0.0912 | train_accuracy: 0.9844 | test_accuracy: 0.9612\n",
      "[  406]/[  468] | train_loss: 0.1015 | train_accuracy: 0.9609 | test_accuracy: 0.9611\n",
      "[  407]/[  468] | train_loss: 0.1130 | train_accuracy: 0.9688 | test_accuracy: 0.9626\n",
      "[  408]/[  468] | train_loss: 0.1258 | train_accuracy: 0.9453 | test_accuracy: 0.9617\n",
      "[  409]/[  468] | train_loss: 0.0798 | train_accuracy: 0.9844 | test_accuracy: 0.9619\n",
      "[  410]/[  468] | train_loss: 0.1831 | train_accuracy: 0.9453 | test_accuracy: 0.9619\n",
      "[  411]/[  468] | train_loss: 0.1470 | train_accuracy: 0.9531 | test_accuracy: 0.9604\n",
      "[  412]/[  468] | train_loss: 0.1215 | train_accuracy: 0.9531 | test_accuracy: 0.9583\n",
      "[  413]/[  468] | train_loss: 0.0480 | train_accuracy: 0.9922 | test_accuracy: 0.9564\n",
      "[  414]/[  468] | train_loss: 0.1567 | train_accuracy: 0.9766 | test_accuracy: 0.9557\n",
      "[  415]/[  468] | train_loss: 0.1771 | train_accuracy: 0.9297 | test_accuracy: 0.9559\n",
      "[  416]/[  468] | train_loss: 0.1850 | train_accuracy: 0.9453 | test_accuracy: 0.9562\n",
      "[  417]/[  468] | train_loss: 0.1564 | train_accuracy: 0.9688 | test_accuracy: 0.9581\n",
      "[  418]/[  468] | train_loss: 0.1092 | train_accuracy: 0.9688 | test_accuracy: 0.9578\n",
      "[  419]/[  468] | train_loss: 0.1568 | train_accuracy: 0.9531 | test_accuracy: 0.9587\n",
      "[  420]/[  468] | train_loss: 0.0951 | train_accuracy: 0.9609 | test_accuracy: 0.9594\n",
      "[  421]/[  468] | train_loss: 0.0982 | train_accuracy: 0.9766 | test_accuracy: 0.9602\n",
      "[  422]/[  468] | train_loss: 0.1157 | train_accuracy: 0.9688 | test_accuracy: 0.9607\n",
      "[  423]/[  468] | train_loss: 0.1660 | train_accuracy: 0.9531 | test_accuracy: 0.9609\n",
      "[  424]/[  468] | train_loss: 0.1893 | train_accuracy: 0.9531 | test_accuracy: 0.9613\n",
      "[  425]/[  468] | train_loss: 0.1404 | train_accuracy: 0.9688 | test_accuracy: 0.9617\n",
      "[  426]/[  468] | train_loss: 0.1131 | train_accuracy: 0.9766 | test_accuracy: 0.9613\n",
      "[  427]/[  468] | train_loss: 0.0656 | train_accuracy: 0.9766 | test_accuracy: 0.9595\n",
      "[  428]/[  468] | train_loss: 0.1063 | train_accuracy: 0.9688 | test_accuracy: 0.9593\n",
      "[  429]/[  468] | train_loss: 0.2258 | train_accuracy: 0.9609 | test_accuracy: 0.9602\n",
      "[  430]/[  468] | train_loss: 0.0791 | train_accuracy: 0.9844 | test_accuracy: 0.9610\n",
      "[  431]/[  468] | train_loss: 0.1704 | train_accuracy: 0.9453 | test_accuracy: 0.9621\n",
      "[  432]/[  468] | train_loss: 0.1143 | train_accuracy: 0.9844 | test_accuracy: 0.9624\n",
      "[  433]/[  468] | train_loss: 0.0926 | train_accuracy: 0.9844 | test_accuracy: 0.9622\n",
      "[  434]/[  468] | train_loss: 0.1890 | train_accuracy: 0.9375 | test_accuracy: 0.9634\n",
      "[  435]/[  468] | train_loss: 0.1240 | train_accuracy: 0.9609 | test_accuracy: 0.9627\n",
      "[  436]/[  468] | train_loss: 0.1275 | train_accuracy: 0.9609 | test_accuracy: 0.9628\n",
      "[  437]/[  468] | train_loss: 0.1091 | train_accuracy: 0.9688 | test_accuracy: 0.9626\n",
      "[  438]/[  468] | train_loss: 0.0933 | train_accuracy: 0.9766 | test_accuracy: 0.9632\n",
      "[  439]/[  468] | train_loss: 0.1027 | train_accuracy: 0.9688 | test_accuracy: 0.9631\n",
      "[  440]/[  468] | train_loss: 0.1078 | train_accuracy: 0.9688 | test_accuracy: 0.9631\n",
      "[  441]/[  468] | train_loss: 0.1291 | train_accuracy: 0.9375 | test_accuracy: 0.9626\n",
      "[  442]/[  468] | train_loss: 0.1199 | train_accuracy: 0.9609 | test_accuracy: 0.9623\n",
      "[  443]/[  468] | train_loss: 0.0676 | train_accuracy: 0.9766 | test_accuracy: 0.9624\n",
      "[  444]/[  468] | train_loss: 0.1055 | train_accuracy: 0.9766 | test_accuracy: 0.9621\n",
      "[  445]/[  468] | train_loss: 0.0928 | train_accuracy: 0.9766 | test_accuracy: 0.9611\n",
      "[  446]/[  468] | train_loss: 0.1135 | train_accuracy: 0.9688 | test_accuracy: 0.9605\n",
      "[  447]/[  468] | train_loss: 0.1791 | train_accuracy: 0.9531 | test_accuracy: 0.9611\n",
      "[  448]/[  468] | train_loss: 0.1185 | train_accuracy: 0.9766 | test_accuracy: 0.9626\n",
      "[  449]/[  468] | train_loss: 0.1007 | train_accuracy: 0.9688 | test_accuracy: 0.9633\n",
      "[  450]/[  468] | train_loss: 0.2478 | train_accuracy: 0.9375 | test_accuracy: 0.9626\n",
      "[  451]/[  468] | train_loss: 0.1084 | train_accuracy: 0.9688 | test_accuracy: 0.9630\n",
      "[  452]/[  468] | train_loss: 0.1310 | train_accuracy: 0.9766 | test_accuracy: 0.9624\n",
      "[  453]/[  468] | train_loss: 0.1217 | train_accuracy: 0.9609 | test_accuracy: 0.9624\n",
      "[  454]/[  468] | train_loss: 0.1124 | train_accuracy: 0.9609 | test_accuracy: 0.9629\n",
      "[  455]/[  468] | train_loss: 0.0852 | train_accuracy: 0.9844 | test_accuracy: 0.9619\n",
      "[  456]/[  468] | train_loss: 0.1560 | train_accuracy: 0.9609 | test_accuracy: 0.9624\n",
      "[  457]/[  468] | train_loss: 0.0337 | train_accuracy: 1.0000 | test_accuracy: 0.9618\n",
      "[  458]/[  468] | train_loss: 0.1077 | train_accuracy: 0.9688 | test_accuracy: 0.9603\n",
      "[  459]/[  468] | train_loss: 0.1317 | train_accuracy: 0.9531 | test_accuracy: 0.9590\n",
      "[  460]/[  468] | train_loss: 0.1209 | train_accuracy: 0.9688 | test_accuracy: 0.9597\n",
      "[  461]/[  468] | train_loss: 0.1620 | train_accuracy: 0.9141 | test_accuracy: 0.9608\n",
      "[  462]/[  468] | train_loss: 0.1668 | train_accuracy: 0.9531 | test_accuracy: 0.9617\n",
      "[  463]/[  468] | train_loss: 0.1815 | train_accuracy: 0.9609 | test_accuracy: 0.9614\n",
      "[  464]/[  468] | train_loss: 0.1387 | train_accuracy: 0.9531 | test_accuracy: 0.9594\n",
      "[  465]/[  468] | train_loss: 0.0565 | train_accuracy: 0.9922 | test_accuracy: 0.9563\n",
      "[  466]/[  468] | train_loss: 0.1827 | train_accuracy: 0.9375 | test_accuracy: 0.9560\n",
      "[  467]/[  468] | train_loss: 0.0978 | train_accuracy: 0.9688 | test_accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "network = create_model(label_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "for idx, (train_input, train_label) in enumerate(train_dataset):\n",
    "    grads = grad(network, train_input, train_label)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
    "    \n",
    "    train_loss = loss_fn(network, train_input, train_label)\n",
    "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "    \n",
    "    for test_input, test_label in test_dataset:\n",
    "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "        \n",
    "    print(\"[{:5d}]/[{:5d}] | train_loss: {:2.4f} | train_accuracy: {:2.4f} | test_accuracy: {:2.4f}\".\\\n",
    "         format(idx, len(train_data)//batch_size, train_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
