{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "\n",
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)\n",
    "\n",
    "train_data = train_data.astype(np.float32) / 255.\n",
    "test_data = test_data.astype(np.float32) / 255.\n",
    "\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, from_logits=True))\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    return tf.reduce_mean(tf.cast(prediction, dtype=tf.float32))\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten():\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init):\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu():\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "\n",
    "def dropout(rate):\n",
    "    return tf.keras.layers.Dropout(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(model, self).__init__()\n",
    "        weight_init = tf.keras.initializers.glorot_uniform()\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten())\n",
    "        \n",
    "        for i in range(4):\n",
    "            self.model.add(dense(512, weight_init))\n",
    "            self.model.add(relu())\n",
    "            self.model.add(dropout(rate=0.5))\n",
    "            \n",
    "        self.model.add(dense(label_dim, weight_init))\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_data, train_labels\n",
    ")). shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True).\\\n",
    "    repeat(5)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    test_data, test_labels\n",
    ")). shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(len(test_data)).\\\n",
    "    repeat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "[    0/  468] train_loss: 2.3321 | train_accuracy: 0.1562 | test_accuracy: 0.1189\n",
      "[    1/  468] train_loss: 2.3211 | train_accuracy: 0.2812 | test_accuracy: 0.2396\n",
      "[    2/  468] train_loss: 2.3134 | train_accuracy: 0.3281 | test_accuracy: 0.2856\n",
      "[    3/  468] train_loss: 2.2850 | train_accuracy: 0.3047 | test_accuracy: 0.3261\n",
      "[    4/  468] train_loss: 2.2796 | train_accuracy: 0.4297 | test_accuracy: 0.3541\n",
      "[    5/  468] train_loss: 2.1566 | train_accuracy: 0.4375 | test_accuracy: 0.4070\n",
      "[    6/  468] train_loss: 2.2448 | train_accuracy: 0.5000 | test_accuracy: 0.4513\n",
      "[    7/  468] train_loss: 2.2406 | train_accuracy: 0.4844 | test_accuracy: 0.4851\n",
      "[    8/  468] train_loss: 2.2364 | train_accuracy: 0.4453 | test_accuracy: 0.5027\n",
      "[    9/  468] train_loss: 2.2290 | train_accuracy: 0.5625 | test_accuracy: 0.4989\n",
      "[   10/  468] train_loss: 2.1757 | train_accuracy: 0.4922 | test_accuracy: 0.5141\n",
      "[   11/  468] train_loss: 2.0926 | train_accuracy: 0.5859 | test_accuracy: 0.5340\n",
      "[   12/  468] train_loss: 2.0809 | train_accuracy: 0.4922 | test_accuracy: 0.5482\n",
      "[   13/  468] train_loss: 1.9757 | train_accuracy: 0.5391 | test_accuracy: 0.5483\n",
      "[   14/  468] train_loss: 2.0163 | train_accuracy: 0.5469 | test_accuracy: 0.5500\n",
      "[   15/  468] train_loss: 1.9004 | train_accuracy: 0.5391 | test_accuracy: 0.5287\n",
      "[   16/  468] train_loss: 1.9070 | train_accuracy: 0.5000 | test_accuracy: 0.4978\n",
      "[   17/  468] train_loss: 1.9045 | train_accuracy: 0.5312 | test_accuracy: 0.4927\n",
      "[   18/  468] train_loss: 1.7981 | train_accuracy: 0.4375 | test_accuracy: 0.4885\n",
      "[   19/  468] train_loss: 1.8825 | train_accuracy: 0.4219 | test_accuracy: 0.5014\n",
      "[   20/  468] train_loss: 1.7722 | train_accuracy: 0.5312 | test_accuracy: 0.5141\n",
      "[   21/  468] train_loss: 1.6750 | train_accuracy: 0.5078 | test_accuracy: 0.5256\n",
      "[   22/  468] train_loss: 1.7126 | train_accuracy: 0.5703 | test_accuracy: 0.5511\n",
      "[   23/  468] train_loss: 1.6630 | train_accuracy: 0.5547 | test_accuracy: 0.5794\n",
      "[   24/  468] train_loss: 1.6188 | train_accuracy: 0.6406 | test_accuracy: 0.6091\n",
      "[   25/  468] train_loss: 1.6339 | train_accuracy: 0.6172 | test_accuracy: 0.6288\n",
      "[   26/  468] train_loss: 1.3297 | train_accuracy: 0.6484 | test_accuracy: 0.6445\n",
      "[   27/  468] train_loss: 1.5238 | train_accuracy: 0.6484 | test_accuracy: 0.6657\n",
      "[   28/  468] train_loss: 1.3524 | train_accuracy: 0.6484 | test_accuracy: 0.6904\n",
      "[   29/  468] train_loss: 1.3192 | train_accuracy: 0.7266 | test_accuracy: 0.7072\n",
      "[   30/  468] train_loss: 1.2655 | train_accuracy: 0.7188 | test_accuracy: 0.7179\n",
      "[   31/  468] train_loss: 1.3085 | train_accuracy: 0.7812 | test_accuracy: 0.7211\n",
      "[   32/  468] train_loss: 1.1802 | train_accuracy: 0.7188 | test_accuracy: 0.7157\n",
      "[   33/  468] train_loss: 1.1938 | train_accuracy: 0.7031 | test_accuracy: 0.7175\n",
      "[   34/  468] train_loss: 1.3299 | train_accuracy: 0.6641 | test_accuracy: 0.7347\n",
      "[   35/  468] train_loss: 1.1162 | train_accuracy: 0.7109 | test_accuracy: 0.7500\n",
      "[   36/  468] train_loss: 1.1752 | train_accuracy: 0.7422 | test_accuracy: 0.7583\n",
      "[   37/  468] train_loss: 1.1388 | train_accuracy: 0.7656 | test_accuracy: 0.7616\n",
      "[   38/  468] train_loss: 1.2238 | train_accuracy: 0.7578 | test_accuracy: 0.7653\n",
      "[   39/  468] train_loss: 1.0130 | train_accuracy: 0.7578 | test_accuracy: 0.7690\n",
      "[   40/  468] train_loss: 1.1237 | train_accuracy: 0.7891 | test_accuracy: 0.7637\n",
      "[   41/  468] train_loss: 1.0241 | train_accuracy: 0.8047 | test_accuracy: 0.7581\n",
      "[   42/  468] train_loss: 0.9953 | train_accuracy: 0.7969 | test_accuracy: 0.7498\n",
      "[   43/  468] train_loss: 0.9980 | train_accuracy: 0.7344 | test_accuracy: 0.7481\n",
      "[   44/  468] train_loss: 1.1768 | train_accuracy: 0.7344 | test_accuracy: 0.7603\n",
      "[   45/  468] train_loss: 0.8748 | train_accuracy: 0.7812 | test_accuracy: 0.7804\n",
      "[   46/  468] train_loss: 0.7622 | train_accuracy: 0.8359 | test_accuracy: 0.7913\n",
      "[   47/  468] train_loss: 0.7500 | train_accuracy: 0.8438 | test_accuracy: 0.7942\n",
      "[   48/  468] train_loss: 1.0438 | train_accuracy: 0.7266 | test_accuracy: 0.7973\n",
      "[   49/  468] train_loss: 0.9389 | train_accuracy: 0.7734 | test_accuracy: 0.8047\n",
      "[   50/  468] train_loss: 1.0344 | train_accuracy: 0.7578 | test_accuracy: 0.8097\n",
      "[   51/  468] train_loss: 0.7943 | train_accuracy: 0.7969 | test_accuracy: 0.8203\n",
      "[   52/  468] train_loss: 0.6424 | train_accuracy: 0.8906 | test_accuracy: 0.8283\n",
      "[   53/  468] train_loss: 0.6089 | train_accuracy: 0.8750 | test_accuracy: 0.8293\n",
      "[   54/  468] train_loss: 0.9443 | train_accuracy: 0.8125 | test_accuracy: 0.8328\n",
      "[   55/  468] train_loss: 0.8456 | train_accuracy: 0.8359 | test_accuracy: 0.8401\n",
      "[   56/  468] train_loss: 0.9355 | train_accuracy: 0.7812 | test_accuracy: 0.8457\n",
      "[   57/  468] train_loss: 0.7874 | train_accuracy: 0.8516 | test_accuracy: 0.8525\n",
      "[   58/  468] train_loss: 0.7978 | train_accuracy: 0.8516 | test_accuracy: 0.8582\n",
      "[   59/  468] train_loss: 0.8016 | train_accuracy: 0.8203 | test_accuracy: 0.8556\n",
      "[   60/  468] train_loss: 0.7581 | train_accuracy: 0.8359 | test_accuracy: 0.8478\n",
      "[   61/  468] train_loss: 1.0137 | train_accuracy: 0.7891 | test_accuracy: 0.8419\n",
      "[   62/  468] train_loss: 0.8962 | train_accuracy: 0.8125 | test_accuracy: 0.8446\n",
      "[   63/  468] train_loss: 0.6818 | train_accuracy: 0.8125 | test_accuracy: 0.8516\n",
      "[   64/  468] train_loss: 0.7909 | train_accuracy: 0.8203 | test_accuracy: 0.8628\n",
      "[   65/  468] train_loss: 0.6165 | train_accuracy: 0.8828 | test_accuracy: 0.8706\n",
      "[   66/  468] train_loss: 0.7776 | train_accuracy: 0.8281 | test_accuracy: 0.8720\n",
      "[   67/  468] train_loss: 0.6051 | train_accuracy: 0.8906 | test_accuracy: 0.8756\n",
      "[   68/  468] train_loss: 0.6931 | train_accuracy: 0.8516 | test_accuracy: 0.8747\n",
      "[   69/  468] train_loss: 0.7114 | train_accuracy: 0.8438 | test_accuracy: 0.8728\n",
      "[   70/  468] train_loss: 0.5646 | train_accuracy: 0.8984 | test_accuracy: 0.8730\n",
      "[   71/  468] train_loss: 0.7528 | train_accuracy: 0.8203 | test_accuracy: 0.8745\n",
      "[   72/  468] train_loss: 0.6451 | train_accuracy: 0.8906 | test_accuracy: 0.8754\n",
      "[   73/  468] train_loss: 0.7329 | train_accuracy: 0.8750 | test_accuracy: 0.8779\n",
      "[   74/  468] train_loss: 0.5052 | train_accuracy: 0.8984 | test_accuracy: 0.8800\n",
      "[   75/  468] train_loss: 0.5381 | train_accuracy: 0.8906 | test_accuracy: 0.8831\n",
      "[   76/  468] train_loss: 0.5803 | train_accuracy: 0.8750 | test_accuracy: 0.8843\n",
      "[   77/  468] train_loss: 0.4492 | train_accuracy: 0.8984 | test_accuracy: 0.8870\n",
      "[   78/  468] train_loss: 0.4643 | train_accuracy: 0.9375 | test_accuracy: 0.8898\n",
      "[   79/  468] train_loss: 0.5264 | train_accuracy: 0.8906 | test_accuracy: 0.8924\n",
      "[   80/  468] train_loss: 0.5086 | train_accuracy: 0.9062 | test_accuracy: 0.8935\n",
      "[   81/  468] train_loss: 0.5266 | train_accuracy: 0.9141 | test_accuracy: 0.8923\n",
      "[   82/  468] train_loss: 0.3716 | train_accuracy: 0.9297 | test_accuracy: 0.8909\n",
      "[   83/  468] train_loss: 0.4210 | train_accuracy: 0.8828 | test_accuracy: 0.8893\n",
      "[   84/  468] train_loss: 0.5179 | train_accuracy: 0.8750 | test_accuracy: 0.8914\n",
      "[   85/  468] train_loss: 0.5067 | train_accuracy: 0.8906 | test_accuracy: 0.8953\n",
      "[   86/  468] train_loss: 0.4353 | train_accuracy: 0.9297 | test_accuracy: 0.8943\n",
      "[   87/  468] train_loss: 0.6685 | train_accuracy: 0.8359 | test_accuracy: 0.8969\n",
      "[   88/  468] train_loss: 0.4648 | train_accuracy: 0.9062 | test_accuracy: 0.8977\n",
      "[   89/  468] train_loss: 0.5451 | train_accuracy: 0.8984 | test_accuracy: 0.8993\n",
      "[   90/  468] train_loss: 0.5435 | train_accuracy: 0.9062 | test_accuracy: 0.8989\n",
      "[   91/  468] train_loss: 0.7733 | train_accuracy: 0.8516 | test_accuracy: 0.8993\n",
      "[   92/  468] train_loss: 0.5712 | train_accuracy: 0.8906 | test_accuracy: 0.8999\n",
      "[   93/  468] train_loss: 0.5138 | train_accuracy: 0.9297 | test_accuracy: 0.9008\n",
      "[   94/  468] train_loss: 0.5463 | train_accuracy: 0.8828 | test_accuracy: 0.9008\n",
      "[   95/  468] train_loss: 0.5288 | train_accuracy: 0.8672 | test_accuracy: 0.8985\n",
      "[   96/  468] train_loss: 0.5673 | train_accuracy: 0.8750 | test_accuracy: 0.8978\n",
      "[   97/  468] train_loss: 0.4631 | train_accuracy: 0.9141 | test_accuracy: 0.8951\n",
      "[   98/  468] train_loss: 0.8261 | train_accuracy: 0.8828 | test_accuracy: 0.8945\n",
      "[   99/  468] train_loss: 0.4670 | train_accuracy: 0.9219 | test_accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  100/  468] train_loss: 0.3567 | train_accuracy: 0.9375 | test_accuracy: 0.8963\n",
      "[  101/  468] train_loss: 0.4539 | train_accuracy: 0.8906 | test_accuracy: 0.9002\n",
      "[  102/  468] train_loss: 0.5126 | train_accuracy: 0.8906 | test_accuracy: 0.9039\n",
      "[  103/  468] train_loss: 0.4886 | train_accuracy: 0.8984 | test_accuracy: 0.9038\n",
      "[  104/  468] train_loss: 0.5827 | train_accuracy: 0.8984 | test_accuracy: 0.9047\n",
      "[  105/  468] train_loss: 0.4299 | train_accuracy: 0.9062 | test_accuracy: 0.9048\n",
      "[  106/  468] train_loss: 0.4808 | train_accuracy: 0.9062 | test_accuracy: 0.9051\n",
      "[  107/  468] train_loss: 0.4471 | train_accuracy: 0.9375 | test_accuracy: 0.9069\n",
      "[  108/  468] train_loss: 0.6375 | train_accuracy: 0.9141 | test_accuracy: 0.9093\n",
      "[  109/  468] train_loss: 0.3774 | train_accuracy: 0.9375 | test_accuracy: 0.9093\n",
      "[  110/  468] train_loss: 0.4992 | train_accuracy: 0.8828 | test_accuracy: 0.9097\n",
      "[  111/  468] train_loss: 0.5875 | train_accuracy: 0.9062 | test_accuracy: 0.9061\n",
      "[  112/  468] train_loss: 0.6090 | train_accuracy: 0.8828 | test_accuracy: 0.9041\n",
      "[  113/  468] train_loss: 0.4935 | train_accuracy: 0.9062 | test_accuracy: 0.9039\n",
      "[  114/  468] train_loss: 0.3986 | train_accuracy: 0.8984 | test_accuracy: 0.9028\n",
      "[  115/  468] train_loss: 0.4374 | train_accuracy: 0.9297 | test_accuracy: 0.9032\n",
      "[  116/  468] train_loss: 0.4308 | train_accuracy: 0.9062 | test_accuracy: 0.9038\n",
      "[  117/  468] train_loss: 0.3770 | train_accuracy: 0.9531 | test_accuracy: 0.9083\n",
      "[  118/  468] train_loss: 0.4004 | train_accuracy: 0.9219 | test_accuracy: 0.9109\n",
      "[  119/  468] train_loss: 0.6606 | train_accuracy: 0.8594 | test_accuracy: 0.9125\n",
      "[  120/  468] train_loss: 0.4464 | train_accuracy: 0.8984 | test_accuracy: 0.9132\n",
      "[  121/  468] train_loss: 0.4614 | train_accuracy: 0.8906 | test_accuracy: 0.9139\n",
      "[  122/  468] train_loss: 0.4430 | train_accuracy: 0.8984 | test_accuracy: 0.9136\n",
      "[  123/  468] train_loss: 0.4374 | train_accuracy: 0.8984 | test_accuracy: 0.9118\n",
      "[  124/  468] train_loss: 0.4951 | train_accuracy: 0.8594 | test_accuracy: 0.9122\n",
      "[  125/  468] train_loss: 0.3869 | train_accuracy: 0.9141 | test_accuracy: 0.9140\n",
      "[  126/  468] train_loss: 0.4237 | train_accuracy: 0.9219 | test_accuracy: 0.9146\n",
      "[  127/  468] train_loss: 0.3996 | train_accuracy: 0.9062 | test_accuracy: 0.9139\n",
      "[  128/  468] train_loss: 0.3507 | train_accuracy: 0.9531 | test_accuracy: 0.9133\n",
      "[  129/  468] train_loss: 0.4044 | train_accuracy: 0.9297 | test_accuracy: 0.9141\n",
      "[  130/  468] train_loss: 0.5910 | train_accuracy: 0.8906 | test_accuracy: 0.9154\n",
      "[  131/  468] train_loss: 0.4142 | train_accuracy: 0.9375 | test_accuracy: 0.9171\n",
      "[  132/  468] train_loss: 0.3522 | train_accuracy: 0.9141 | test_accuracy: 0.9170\n",
      "[  133/  468] train_loss: 0.4053 | train_accuracy: 0.9141 | test_accuracy: 0.9172\n",
      "[  134/  468] train_loss: 0.5268 | train_accuracy: 0.9219 | test_accuracy: 0.9189\n",
      "[  135/  468] train_loss: 0.5003 | train_accuracy: 0.8984 | test_accuracy: 0.9193\n",
      "[  136/  468] train_loss: 0.3123 | train_accuracy: 0.9219 | test_accuracy: 0.9185\n",
      "[  137/  468] train_loss: 0.4348 | train_accuracy: 0.9062 | test_accuracy: 0.9180\n",
      "[  138/  468] train_loss: 0.4718 | train_accuracy: 0.9062 | test_accuracy: 0.9185\n",
      "[  139/  468] train_loss: 0.3182 | train_accuracy: 0.9609 | test_accuracy: 0.9205\n",
      "[  140/  468] train_loss: 0.3079 | train_accuracy: 0.9375 | test_accuracy: 0.9217\n",
      "[  141/  468] train_loss: 0.4248 | train_accuracy: 0.9219 | test_accuracy: 0.9235\n",
      "[  142/  468] train_loss: 0.7218 | train_accuracy: 0.9141 | test_accuracy: 0.9224\n",
      "[  143/  468] train_loss: 0.5022 | train_accuracy: 0.9062 | test_accuracy: 0.9201\n",
      "[  144/  468] train_loss: 0.3769 | train_accuracy: 0.9219 | test_accuracy: 0.9191\n",
      "[  145/  468] train_loss: 0.4728 | train_accuracy: 0.9062 | test_accuracy: 0.9181\n",
      "[  146/  468] train_loss: 0.3957 | train_accuracy: 0.9141 | test_accuracy: 0.9168\n",
      "[  147/  468] train_loss: 0.2981 | train_accuracy: 0.9297 | test_accuracy: 0.9163\n",
      "[  148/  468] train_loss: 0.3913 | train_accuracy: 0.9453 | test_accuracy: 0.9181\n",
      "[  149/  468] train_loss: 0.2353 | train_accuracy: 0.9609 | test_accuracy: 0.9194\n",
      "[  150/  468] train_loss: 0.2664 | train_accuracy: 0.9531 | test_accuracy: 0.9202\n",
      "[  151/  468] train_loss: 0.3589 | train_accuracy: 0.9453 | test_accuracy: 0.9206\n",
      "[  152/  468] train_loss: 0.4563 | train_accuracy: 0.9141 | test_accuracy: 0.9185\n",
      "[  153/  468] train_loss: 0.3062 | train_accuracy: 0.9375 | test_accuracy: 0.9183\n",
      "[  154/  468] train_loss: 0.4601 | train_accuracy: 0.9141 | test_accuracy: 0.9172\n",
      "[  155/  468] train_loss: 0.4437 | train_accuracy: 0.9062 | test_accuracy: 0.9202\n",
      "[  156/  468] train_loss: 0.4585 | train_accuracy: 0.9219 | test_accuracy: 0.9223\n",
      "[  157/  468] train_loss: 0.4447 | train_accuracy: 0.9219 | test_accuracy: 0.9234\n",
      "[  158/  468] train_loss: 0.3415 | train_accuracy: 0.9219 | test_accuracy: 0.9248\n",
      "[  159/  468] train_loss: 0.3539 | train_accuracy: 0.9375 | test_accuracy: 0.9256\n",
      "[  160/  468] train_loss: 0.3658 | train_accuracy: 0.9062 | test_accuracy: 0.9270\n",
      "[  161/  468] train_loss: 0.3648 | train_accuracy: 0.9453 | test_accuracy: 0.9259\n",
      "[  162/  468] train_loss: 0.4653 | train_accuracy: 0.9141 | test_accuracy: 0.9257\n",
      "[  163/  468] train_loss: 0.3740 | train_accuracy: 0.9219 | test_accuracy: 0.9247\n",
      "[  164/  468] train_loss: 0.3641 | train_accuracy: 0.9297 | test_accuracy: 0.9225\n",
      "[  165/  468] train_loss: 0.3805 | train_accuracy: 0.9141 | test_accuracy: 0.9228\n",
      "[  166/  468] train_loss: 0.2907 | train_accuracy: 0.9531 | test_accuracy: 0.9242\n",
      "[  167/  468] train_loss: 0.3568 | train_accuracy: 0.9453 | test_accuracy: 0.9253\n",
      "[  168/  468] train_loss: 0.3263 | train_accuracy: 0.9531 | test_accuracy: 0.9286\n",
      "[  169/  468] train_loss: 0.2633 | train_accuracy: 0.8984 | test_accuracy: 0.9308\n",
      "[  170/  468] train_loss: 0.3210 | train_accuracy: 0.9375 | test_accuracy: 0.9298\n",
      "[  171/  468] train_loss: 0.4062 | train_accuracy: 0.9531 | test_accuracy: 0.9306\n",
      "[  172/  468] train_loss: 0.2749 | train_accuracy: 0.9453 | test_accuracy: 0.9310\n",
      "[  173/  468] train_loss: 0.3435 | train_accuracy: 0.9531 | test_accuracy: 0.9319\n",
      "[  174/  468] train_loss: 0.5051 | train_accuracy: 0.8984 | test_accuracy: 0.9314\n",
      "[  175/  468] train_loss: 0.3711 | train_accuracy: 0.9141 | test_accuracy: 0.9324\n",
      "[  176/  468] train_loss: 0.2610 | train_accuracy: 0.9141 | test_accuracy: 0.9327\n",
      "[  177/  468] train_loss: 0.3360 | train_accuracy: 0.9531 | test_accuracy: 0.9324\n",
      "[  178/  468] train_loss: 0.3785 | train_accuracy: 0.9062 | test_accuracy: 0.9309\n",
      "[  179/  468] train_loss: 0.3183 | train_accuracy: 0.9062 | test_accuracy: 0.9307\n",
      "[  180/  468] train_loss: 0.4097 | train_accuracy: 0.9453 | test_accuracy: 0.9312\n",
      "[  181/  468] train_loss: 0.4167 | train_accuracy: 0.9375 | test_accuracy: 0.9302\n",
      "[  182/  468] train_loss: 0.3811 | train_accuracy: 0.9219 | test_accuracy: 0.9304\n",
      "[  183/  468] train_loss: 0.2330 | train_accuracy: 0.9531 | test_accuracy: 0.9306\n",
      "[  184/  468] train_loss: 0.3481 | train_accuracy: 0.9453 | test_accuracy: 0.9312\n",
      "[  185/  468] train_loss: 0.3596 | train_accuracy: 0.9297 | test_accuracy: 0.9324\n",
      "[  186/  468] train_loss: 0.3790 | train_accuracy: 0.9219 | test_accuracy: 0.9342\n",
      "[  187/  468] train_loss: 0.3583 | train_accuracy: 0.9453 | test_accuracy: 0.9340\n",
      "[  188/  468] train_loss: 0.3469 | train_accuracy: 0.9297 | test_accuracy: 0.9330\n",
      "[  189/  468] train_loss: 0.3106 | train_accuracy: 0.9688 | test_accuracy: 0.9320\n",
      "[  190/  468] train_loss: 0.5362 | train_accuracy: 0.8906 | test_accuracy: 0.9302\n",
      "[  191/  468] train_loss: 0.3189 | train_accuracy: 0.9219 | test_accuracy: 0.9294\n",
      "[  192/  468] train_loss: 0.2816 | train_accuracy: 0.9766 | test_accuracy: 0.9287\n",
      "[  193/  468] train_loss: 0.4530 | train_accuracy: 0.9609 | test_accuracy: 0.9294\n",
      "[  194/  468] train_loss: 0.2450 | train_accuracy: 0.9453 | test_accuracy: 0.9323\n",
      "[  195/  468] train_loss: 0.3664 | train_accuracy: 0.9531 | test_accuracy: 0.9346\n",
      "[  196/  468] train_loss: 0.4853 | train_accuracy: 0.9141 | test_accuracy: 0.9361\n",
      "[  197/  468] train_loss: 0.4602 | train_accuracy: 0.9219 | test_accuracy: 0.9357\n",
      "[  198/  468] train_loss: 0.4091 | train_accuracy: 0.9453 | test_accuracy: 0.9359\n",
      "[  199/  468] train_loss: 0.2765 | train_accuracy: 0.9609 | test_accuracy: 0.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200/  468] train_loss: 0.2922 | train_accuracy: 0.9609 | test_accuracy: 0.9356\n",
      "[  201/  468] train_loss: 0.2536 | train_accuracy: 0.9531 | test_accuracy: 0.9345\n",
      "[  202/  468] train_loss: 0.3375 | train_accuracy: 0.9141 | test_accuracy: 0.9343\n",
      "[  203/  468] train_loss: 0.2630 | train_accuracy: 0.9688 | test_accuracy: 0.9353\n",
      "[  204/  468] train_loss: 0.3966 | train_accuracy: 0.9062 | test_accuracy: 0.9376\n",
      "[  205/  468] train_loss: 0.1863 | train_accuracy: 0.9375 | test_accuracy: 0.9361\n",
      "[  206/  468] train_loss: 0.2942 | train_accuracy: 0.9531 | test_accuracy: 0.9335\n",
      "[  207/  468] train_loss: 0.4989 | train_accuracy: 0.8906 | test_accuracy: 0.9307\n",
      "[  208/  468] train_loss: 0.3160 | train_accuracy: 0.9531 | test_accuracy: 0.9268\n",
      "[  209/  468] train_loss: 0.2426 | train_accuracy: 0.9688 | test_accuracy: 0.9237\n",
      "[  210/  468] train_loss: 0.3659 | train_accuracy: 0.9219 | test_accuracy: 0.9226\n",
      "[  211/  468] train_loss: 0.3595 | train_accuracy: 0.9297 | test_accuracy: 0.9242\n",
      "[  212/  468] train_loss: 0.3175 | train_accuracy: 0.9141 | test_accuracy: 0.9267\n",
      "[  213/  468] train_loss: 0.4312 | train_accuracy: 0.9141 | test_accuracy: 0.9311\n",
      "[  214/  468] train_loss: 0.3007 | train_accuracy: 0.9453 | test_accuracy: 0.9370\n",
      "[  215/  468] train_loss: 0.3903 | train_accuracy: 0.9453 | test_accuracy: 0.9425\n",
      "[  216/  468] train_loss: 0.3559 | train_accuracy: 0.9297 | test_accuracy: 0.9429\n",
      "[  217/  468] train_loss: 0.2122 | train_accuracy: 0.9766 | test_accuracy: 0.9408\n",
      "[  218/  468] train_loss: 0.3725 | train_accuracy: 0.9062 | test_accuracy: 0.9397\n",
      "[  219/  468] train_loss: 0.2662 | train_accuracy: 0.9453 | test_accuracy: 0.9363\n",
      "[  220/  468] train_loss: 0.1996 | train_accuracy: 0.9688 | test_accuracy: 0.9337\n",
      "[  221/  468] train_loss: 0.2375 | train_accuracy: 0.9531 | test_accuracy: 0.9318\n",
      "[  222/  468] train_loss: 0.4425 | train_accuracy: 0.9062 | test_accuracy: 0.9315\n",
      "[  223/  468] train_loss: 0.3027 | train_accuracy: 0.9453 | test_accuracy: 0.9299\n",
      "[  224/  468] train_loss: 0.3147 | train_accuracy: 0.9297 | test_accuracy: 0.9307\n",
      "[  225/  468] train_loss: 0.4029 | train_accuracy: 0.9219 | test_accuracy: 0.9332\n",
      "[  226/  468] train_loss: 0.3052 | train_accuracy: 0.9453 | test_accuracy: 0.9371\n",
      "[  227/  468] train_loss: 0.3703 | train_accuracy: 0.9062 | test_accuracy: 0.9392\n",
      "[  228/  468] train_loss: 0.2744 | train_accuracy: 0.9531 | test_accuracy: 0.9399\n",
      "[  229/  468] train_loss: 0.4902 | train_accuracy: 0.9141 | test_accuracy: 0.9411\n",
      "[  230/  468] train_loss: 0.3762 | train_accuracy: 0.9531 | test_accuracy: 0.9412\n",
      "[  231/  468] train_loss: 0.3384 | train_accuracy: 0.9219 | test_accuracy: 0.9395\n",
      "[  232/  468] train_loss: 0.2392 | train_accuracy: 0.9531 | test_accuracy: 0.9378\n",
      "[  233/  468] train_loss: 0.2958 | train_accuracy: 0.9531 | test_accuracy: 0.9370\n",
      "[  234/  468] train_loss: 0.3084 | train_accuracy: 0.9531 | test_accuracy: 0.9373\n",
      "[  235/  468] train_loss: 0.2526 | train_accuracy: 0.9453 | test_accuracy: 0.9374\n",
      "[  236/  468] train_loss: 0.3170 | train_accuracy: 0.9141 | test_accuracy: 0.9378\n",
      "[  237/  468] train_loss: 0.3178 | train_accuracy: 0.9453 | test_accuracy: 0.9396\n",
      "[  238/  468] train_loss: 0.3909 | train_accuracy: 0.9297 | test_accuracy: 0.9408\n",
      "[  239/  468] train_loss: 0.2883 | train_accuracy: 0.9688 | test_accuracy: 0.9413\n",
      "[  240/  468] train_loss: 0.2604 | train_accuracy: 0.9531 | test_accuracy: 0.9420\n",
      "[  241/  468] train_loss: 0.2714 | train_accuracy: 0.9609 | test_accuracy: 0.9412\n",
      "[  242/  468] train_loss: 0.2073 | train_accuracy: 0.9453 | test_accuracy: 0.9391\n",
      "[  243/  468] train_loss: 0.2919 | train_accuracy: 0.9453 | test_accuracy: 0.9384\n",
      "[  244/  468] train_loss: 0.3485 | train_accuracy: 0.9375 | test_accuracy: 0.9371\n",
      "[  245/  468] train_loss: 0.1582 | train_accuracy: 0.9688 | test_accuracy: 0.9355\n",
      "[  246/  468] train_loss: 0.4899 | train_accuracy: 0.9297 | test_accuracy: 0.9351\n",
      "[  247/  468] train_loss: 0.4246 | train_accuracy: 0.9297 | test_accuracy: 0.9349\n",
      "[  248/  468] train_loss: 0.2053 | train_accuracy: 0.9375 | test_accuracy: 0.9364\n",
      "[  249/  468] train_loss: 0.2920 | train_accuracy: 0.9609 | test_accuracy: 0.9367\n",
      "[  250/  468] train_loss: 0.2610 | train_accuracy: 0.9531 | test_accuracy: 0.9374\n",
      "[  251/  468] train_loss: 0.2669 | train_accuracy: 0.9453 | test_accuracy: 0.9384\n",
      "[  252/  468] train_loss: 0.3970 | train_accuracy: 0.9219 | test_accuracy: 0.9396\n",
      "[  253/  468] train_loss: 0.4134 | train_accuracy: 0.9375 | test_accuracy: 0.9424\n",
      "[  254/  468] train_loss: 0.1983 | train_accuracy: 0.9688 | test_accuracy: 0.9416\n",
      "[  255/  468] train_loss: 0.3758 | train_accuracy: 0.9375 | test_accuracy: 0.9424\n",
      "[  256/  468] train_loss: 0.2290 | train_accuracy: 0.9375 | test_accuracy: 0.9420\n",
      "[  257/  468] train_loss: 0.3612 | train_accuracy: 0.9375 | test_accuracy: 0.9431\n",
      "[  258/  468] train_loss: 0.2362 | train_accuracy: 0.9609 | test_accuracy: 0.9426\n",
      "[  259/  468] train_loss: 0.3151 | train_accuracy: 0.9453 | test_accuracy: 0.9427\n",
      "[  260/  468] train_loss: 0.2650 | train_accuracy: 0.9609 | test_accuracy: 0.9408\n",
      "[  261/  468] train_loss: 0.4133 | train_accuracy: 0.9219 | test_accuracy: 0.9416\n",
      "[  262/  468] train_loss: 0.3836 | train_accuracy: 0.9297 | test_accuracy: 0.9418\n",
      "[  263/  468] train_loss: 0.3145 | train_accuracy: 0.9375 | test_accuracy: 0.9431\n",
      "[  264/  468] train_loss: 0.2855 | train_accuracy: 0.9297 | test_accuracy: 0.9457\n",
      "[  265/  468] train_loss: 0.3368 | train_accuracy: 0.9531 | test_accuracy: 0.9448\n",
      "[  266/  468] train_loss: 0.3085 | train_accuracy: 0.9219 | test_accuracy: 0.9431\n",
      "[  267/  468] train_loss: 0.2148 | train_accuracy: 0.9609 | test_accuracy: 0.9428\n",
      "[  268/  468] train_loss: 0.2635 | train_accuracy: 0.9688 | test_accuracy: 0.9424\n",
      "[  269/  468] train_loss: 0.4548 | train_accuracy: 0.9219 | test_accuracy: 0.9430\n",
      "[  270/  468] train_loss: 0.2478 | train_accuracy: 0.9219 | test_accuracy: 0.9424\n",
      "[  271/  468] train_loss: 0.3942 | train_accuracy: 0.9297 | test_accuracy: 0.9427\n",
      "[  272/  468] train_loss: 0.2800 | train_accuracy: 0.9531 | test_accuracy: 0.9421\n",
      "[  273/  468] train_loss: 0.1934 | train_accuracy: 0.9609 | test_accuracy: 0.9408\n",
      "[  274/  468] train_loss: 0.5527 | train_accuracy: 0.9219 | test_accuracy: 0.9391\n",
      "[  275/  468] train_loss: 0.4571 | train_accuracy: 0.9141 | test_accuracy: 0.9371\n",
      "[  276/  468] train_loss: 0.3011 | train_accuracy: 0.9297 | test_accuracy: 0.9356\n",
      "[  277/  468] train_loss: 0.4065 | train_accuracy: 0.9297 | test_accuracy: 0.9357\n",
      "[  278/  468] train_loss: 0.3250 | train_accuracy: 0.9141 | test_accuracy: 0.9372\n",
      "[  279/  468] train_loss: 0.3689 | train_accuracy: 0.9141 | test_accuracy: 0.9397\n",
      "[  280/  468] train_loss: 0.2832 | train_accuracy: 0.9453 | test_accuracy: 0.9411\n",
      "[  281/  468] train_loss: 0.2547 | train_accuracy: 0.9453 | test_accuracy: 0.9415\n",
      "[  282/  468] train_loss: 0.2402 | train_accuracy: 0.9453 | test_accuracy: 0.9416\n",
      "[  283/  468] train_loss: 0.4533 | train_accuracy: 0.9219 | test_accuracy: 0.9409\n",
      "[  284/  468] train_loss: 0.2329 | train_accuracy: 0.9453 | test_accuracy: 0.9406\n",
      "[  285/  468] train_loss: 0.2341 | train_accuracy: 0.9688 | test_accuracy: 0.9390\n",
      "[  286/  468] train_loss: 0.4158 | train_accuracy: 0.9375 | test_accuracy: 0.9386\n",
      "[  287/  468] train_loss: 0.2354 | train_accuracy: 0.9688 | test_accuracy: 0.9411\n",
      "[  288/  468] train_loss: 0.2466 | train_accuracy: 0.9688 | test_accuracy: 0.9429\n",
      "[  289/  468] train_loss: 0.4079 | train_accuracy: 0.9062 | test_accuracy: 0.9442\n",
      "[  290/  468] train_loss: 0.4192 | train_accuracy: 0.9297 | test_accuracy: 0.9450\n",
      "[  291/  468] train_loss: 0.2288 | train_accuracy: 0.9531 | test_accuracy: 0.9442\n",
      "[  292/  468] train_loss: 0.2008 | train_accuracy: 0.9688 | test_accuracy: 0.9446\n",
      "[  293/  468] train_loss: 0.3347 | train_accuracy: 0.9609 | test_accuracy: 0.9455\n",
      "[  294/  468] train_loss: 0.2079 | train_accuracy: 0.9688 | test_accuracy: 0.9452\n",
      "[  295/  468] train_loss: 0.2873 | train_accuracy: 0.9531 | test_accuracy: 0.9446\n",
      "[  296/  468] train_loss: 0.1941 | train_accuracy: 0.9609 | test_accuracy: 0.9437\n",
      "[  297/  468] train_loss: 0.2758 | train_accuracy: 0.9609 | test_accuracy: 0.9428\n",
      "[  298/  468] train_loss: 0.2299 | train_accuracy: 0.9609 | test_accuracy: 0.9408\n",
      "[  299/  468] train_loss: 0.3235 | train_accuracy: 0.9453 | test_accuracy: 0.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  300/  468] train_loss: 0.4497 | train_accuracy: 0.9297 | test_accuracy: 0.9418\n",
      "[  301/  468] train_loss: 0.1952 | train_accuracy: 0.9688 | test_accuracy: 0.9424\n",
      "[  302/  468] train_loss: 0.4779 | train_accuracy: 0.8906 | test_accuracy: 0.9440\n",
      "[  303/  468] train_loss: 0.3298 | train_accuracy: 0.9453 | test_accuracy: 0.9447\n",
      "[  304/  468] train_loss: 0.2841 | train_accuracy: 0.9453 | test_accuracy: 0.9457\n",
      "[  305/  468] train_loss: 0.1736 | train_accuracy: 0.9688 | test_accuracy: 0.9470\n",
      "[  306/  468] train_loss: 0.2182 | train_accuracy: 0.9375 | test_accuracy: 0.9484\n",
      "[  307/  468] train_loss: 0.3386 | train_accuracy: 0.9141 | test_accuracy: 0.9489\n",
      "[  308/  468] train_loss: 0.1802 | train_accuracy: 0.9766 | test_accuracy: 0.9504\n",
      "[  309/  468] train_loss: 0.2875 | train_accuracy: 0.9375 | test_accuracy: 0.9504\n",
      "[  310/  468] train_loss: 0.4193 | train_accuracy: 0.9453 | test_accuracy: 0.9509\n",
      "[  311/  468] train_loss: 0.2073 | train_accuracy: 0.9688 | test_accuracy: 0.9510\n",
      "[  312/  468] train_loss: 0.2918 | train_accuracy: 0.9453 | test_accuracy: 0.9498\n",
      "[  313/  468] train_loss: 0.1542 | train_accuracy: 0.9766 | test_accuracy: 0.9491\n",
      "[  314/  468] train_loss: 0.3310 | train_accuracy: 0.9297 | test_accuracy: 0.9482\n",
      "[  315/  468] train_loss: 0.3769 | train_accuracy: 0.9219 | test_accuracy: 0.9462\n",
      "[  316/  468] train_loss: 0.4567 | train_accuracy: 0.9141 | test_accuracy: 0.9463\n",
      "[  317/  468] train_loss: 0.2245 | train_accuracy: 0.9766 | test_accuracy: 0.9467\n",
      "[  318/  468] train_loss: 0.2628 | train_accuracy: 0.9766 | test_accuracy: 0.9478\n",
      "[  319/  468] train_loss: 0.1676 | train_accuracy: 0.9688 | test_accuracy: 0.9492\n",
      "[  320/  468] train_loss: 0.4115 | train_accuracy: 0.9375 | test_accuracy: 0.9487\n",
      "[  321/  468] train_loss: 0.2452 | train_accuracy: 0.9766 | test_accuracy: 0.9490\n",
      "[  322/  468] train_loss: 0.1865 | train_accuracy: 0.9688 | test_accuracy: 0.9500\n",
      "[  323/  468] train_loss: 0.3491 | train_accuracy: 0.9375 | test_accuracy: 0.9498\n",
      "[  324/  468] train_loss: 0.4200 | train_accuracy: 0.9219 | test_accuracy: 0.9503\n",
      "[  325/  468] train_loss: 0.2489 | train_accuracy: 0.9609 | test_accuracy: 0.9490\n",
      "[  326/  468] train_loss: 0.4430 | train_accuracy: 0.9141 | test_accuracy: 0.9468\n",
      "[  327/  468] train_loss: 0.1419 | train_accuracy: 0.9609 | test_accuracy: 0.9461\n",
      "[  328/  468] train_loss: 0.2650 | train_accuracy: 0.9688 | test_accuracy: 0.9454\n",
      "[  329/  468] train_loss: 0.1136 | train_accuracy: 0.9844 | test_accuracy: 0.9433\n",
      "[  330/  468] train_loss: 0.3220 | train_accuracy: 0.9375 | test_accuracy: 0.9432\n",
      "[  331/  468] train_loss: 0.2322 | train_accuracy: 0.9375 | test_accuracy: 0.9431\n",
      "[  332/  468] train_loss: 0.2191 | train_accuracy: 0.9688 | test_accuracy: 0.9447\n",
      "[  333/  468] train_loss: 0.1845 | train_accuracy: 0.9688 | test_accuracy: 0.9450\n",
      "[  334/  468] train_loss: 0.2317 | train_accuracy: 0.9375 | test_accuracy: 0.9462\n",
      "[  335/  468] train_loss: 0.3077 | train_accuracy: 0.9219 | test_accuracy: 0.9498\n",
      "[  336/  468] train_loss: 0.3065 | train_accuracy: 0.9531 | test_accuracy: 0.9521\n",
      "[  337/  468] train_loss: 0.2680 | train_accuracy: 0.9297 | test_accuracy: 0.9523\n",
      "[  338/  468] train_loss: 0.1472 | train_accuracy: 0.9844 | test_accuracy: 0.9533\n",
      "[  339/  468] train_loss: 0.2221 | train_accuracy: 0.9531 | test_accuracy: 0.9538\n",
      "[  340/  468] train_loss: 0.3519 | train_accuracy: 0.9375 | test_accuracy: 0.9540\n",
      "[  341/  468] train_loss: 0.2207 | train_accuracy: 0.9688 | test_accuracy: 0.9536\n",
      "[  342/  468] train_loss: 0.2137 | train_accuracy: 0.9766 | test_accuracy: 0.9537\n",
      "[  343/  468] train_loss: 0.2200 | train_accuracy: 0.9609 | test_accuracy: 0.9530\n",
      "[  344/  468] train_loss: 0.2176 | train_accuracy: 0.9766 | test_accuracy: 0.9527\n",
      "[  345/  468] train_loss: 0.3021 | train_accuracy: 0.9297 | test_accuracy: 0.9525\n",
      "[  346/  468] train_loss: 0.3515 | train_accuracy: 0.9609 | test_accuracy: 0.9527\n",
      "[  347/  468] train_loss: 0.2354 | train_accuracy: 0.9453 | test_accuracy: 0.9526\n",
      "[  348/  468] train_loss: 0.2673 | train_accuracy: 0.9219 | test_accuracy: 0.9518\n",
      "[  349/  468] train_loss: 0.1895 | train_accuracy: 0.9531 | test_accuracy: 0.9512\n",
      "[  350/  468] train_loss: 0.3235 | train_accuracy: 0.9375 | test_accuracy: 0.9519\n",
      "[  351/  468] train_loss: 0.2825 | train_accuracy: 0.9531 | test_accuracy: 0.9524\n",
      "[  352/  468] train_loss: 0.2079 | train_accuracy: 0.9375 | test_accuracy: 0.9520\n",
      "[  353/  468] train_loss: 0.1956 | train_accuracy: 0.9531 | test_accuracy: 0.9517\n",
      "[  354/  468] train_loss: 0.2131 | train_accuracy: 0.9609 | test_accuracy: 0.9515\n",
      "[  355/  468] train_loss: 0.1455 | train_accuracy: 0.9766 | test_accuracy: 0.9509\n",
      "[  356/  468] train_loss: 0.2474 | train_accuracy: 0.9922 | test_accuracy: 0.9508\n",
      "[  357/  468] train_loss: 0.3298 | train_accuracy: 0.9062 | test_accuracy: 0.9516\n",
      "[  358/  468] train_loss: 0.2968 | train_accuracy: 0.9297 | test_accuracy: 0.9531\n",
      "[  359/  468] train_loss: 0.2547 | train_accuracy: 0.9531 | test_accuracy: 0.9527\n",
      "[  360/  468] train_loss: 0.2579 | train_accuracy: 0.9531 | test_accuracy: 0.9528\n",
      "[  361/  468] train_loss: 0.2867 | train_accuracy: 0.9375 | test_accuracy: 0.9525\n",
      "[  362/  468] train_loss: 0.1847 | train_accuracy: 0.9453 | test_accuracy: 0.9524\n",
      "[  363/  468] train_loss: 0.4082 | train_accuracy: 0.9375 | test_accuracy: 0.9515\n",
      "[  364/  468] train_loss: 0.2659 | train_accuracy: 0.9297 | test_accuracy: 0.9514\n",
      "[  365/  468] train_loss: 0.2120 | train_accuracy: 0.9688 | test_accuracy: 0.9512\n",
      "[  366/  468] train_loss: 0.3201 | train_accuracy: 0.9531 | test_accuracy: 0.9506\n",
      "[  367/  468] train_loss: 0.1929 | train_accuracy: 0.9453 | test_accuracy: 0.9493\n",
      "[  368/  468] train_loss: 0.2393 | train_accuracy: 0.9531 | test_accuracy: 0.9480\n",
      "[  369/  468] train_loss: 0.2779 | train_accuracy: 0.9375 | test_accuracy: 0.9469\n",
      "[  370/  468] train_loss: 0.2244 | train_accuracy: 0.9375 | test_accuracy: 0.9471\n",
      "[  371/  468] train_loss: 0.1990 | train_accuracy: 0.9531 | test_accuracy: 0.9468\n",
      "[  372/  468] train_loss: 0.2259 | train_accuracy: 0.9609 | test_accuracy: 0.9471\n",
      "[  373/  468] train_loss: 0.2517 | train_accuracy: 0.9531 | test_accuracy: 0.9489\n",
      "[  374/  468] train_loss: 0.1494 | train_accuracy: 0.9688 | test_accuracy: 0.9500\n",
      "[  375/  468] train_loss: 0.2425 | train_accuracy: 0.9453 | test_accuracy: 0.9515\n",
      "[  376/  468] train_loss: 0.2113 | train_accuracy: 0.9766 | test_accuracy: 0.9524\n",
      "[  377/  468] train_loss: 0.2065 | train_accuracy: 0.9453 | test_accuracy: 0.9528\n",
      "[  378/  468] train_loss: 0.3647 | train_accuracy: 0.9375 | test_accuracy: 0.9534\n",
      "[  379/  468] train_loss: 0.2708 | train_accuracy: 0.9453 | test_accuracy: 0.9533\n",
      "[  380/  468] train_loss: 0.2104 | train_accuracy: 0.9609 | test_accuracy: 0.9530\n",
      "[  381/  468] train_loss: 0.3380 | train_accuracy: 0.9219 | test_accuracy: 0.9535\n",
      "[  382/  468] train_loss: 0.2351 | train_accuracy: 0.9531 | test_accuracy: 0.9528\n",
      "[  383/  468] train_loss: 0.2908 | train_accuracy: 0.9297 | test_accuracy: 0.9526\n",
      "[  384/  468] train_loss: 0.2048 | train_accuracy: 0.9688 | test_accuracy: 0.9529\n",
      "[  385/  468] train_loss: 0.1778 | train_accuracy: 0.9688 | test_accuracy: 0.9538\n",
      "[  386/  468] train_loss: 0.1896 | train_accuracy: 0.9844 | test_accuracy: 0.9527\n",
      "[  387/  468] train_loss: 0.2226 | train_accuracy: 0.9766 | test_accuracy: 0.9525\n",
      "[  388/  468] train_loss: 0.5102 | train_accuracy: 0.9297 | test_accuracy: 0.9526\n",
      "[  389/  468] train_loss: 0.2131 | train_accuracy: 0.9688 | test_accuracy: 0.9522\n",
      "[  390/  468] train_loss: 0.3114 | train_accuracy: 0.9453 | test_accuracy: 0.9516\n",
      "[  391/  468] train_loss: 0.4142 | train_accuracy: 0.9531 | test_accuracy: 0.9506\n",
      "[  392/  468] train_loss: 0.2854 | train_accuracy: 0.9609 | test_accuracy: 0.9514\n",
      "[  393/  468] train_loss: 0.1658 | train_accuracy: 0.9609 | test_accuracy: 0.9514\n",
      "[  394/  468] train_loss: 0.2663 | train_accuracy: 0.9453 | test_accuracy: 0.9535\n",
      "[  395/  468] train_loss: 0.1956 | train_accuracy: 0.9609 | test_accuracy: 0.9549\n",
      "[  396/  468] train_loss: 0.2438 | train_accuracy: 0.9688 | test_accuracy: 0.9546\n",
      "[  397/  468] train_loss: 0.2119 | train_accuracy: 0.9531 | test_accuracy: 0.9550\n",
      "[  398/  468] train_loss: 0.1721 | train_accuracy: 0.9688 | test_accuracy: 0.9561\n",
      "[  399/  468] train_loss: 0.1499 | train_accuracy: 0.9609 | test_accuracy: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  400/  468] train_loss: 0.2291 | train_accuracy: 0.9531 | test_accuracy: 0.9553\n",
      "[  401/  468] train_loss: 0.2759 | train_accuracy: 0.9375 | test_accuracy: 0.9552\n",
      "[  402/  468] train_loss: 0.2973 | train_accuracy: 0.9453 | test_accuracy: 0.9550\n",
      "[  403/  468] train_loss: 0.1826 | train_accuracy: 0.9688 | test_accuracy: 0.9557\n",
      "[  404/  468] train_loss: 0.2337 | train_accuracy: 0.9375 | test_accuracy: 0.9551\n",
      "[  405/  468] train_loss: 0.2627 | train_accuracy: 0.9688 | test_accuracy: 0.9547\n",
      "[  406/  468] train_loss: 0.1689 | train_accuracy: 0.9844 | test_accuracy: 0.9541\n",
      "[  407/  468] train_loss: 0.1985 | train_accuracy: 0.9453 | test_accuracy: 0.9540\n",
      "[  408/  468] train_loss: 0.2900 | train_accuracy: 0.9531 | test_accuracy: 0.9541\n",
      "[  409/  468] train_loss: 0.2810 | train_accuracy: 0.9609 | test_accuracy: 0.9547\n",
      "[  410/  468] train_loss: 0.2188 | train_accuracy: 0.9609 | test_accuracy: 0.9546\n",
      "[  411/  468] train_loss: 0.2895 | train_accuracy: 0.9609 | test_accuracy: 0.9543\n",
      "[  412/  468] train_loss: 0.1678 | train_accuracy: 0.9688 | test_accuracy: 0.9542\n",
      "[  413/  468] train_loss: 0.1846 | train_accuracy: 0.9688 | test_accuracy: 0.9544\n",
      "[  414/  468] train_loss: 0.3559 | train_accuracy: 0.9609 | test_accuracy: 0.9546\n",
      "[  415/  468] train_loss: 0.1604 | train_accuracy: 0.9844 | test_accuracy: 0.9534\n",
      "[  416/  468] train_loss: 0.4196 | train_accuracy: 0.9375 | test_accuracy: 0.9526\n",
      "[  417/  468] train_loss: 0.3103 | train_accuracy: 0.9609 | test_accuracy: 0.9520\n",
      "[  418/  468] train_loss: 0.1926 | train_accuracy: 0.9609 | test_accuracy: 0.9517\n",
      "[  419/  468] train_loss: 0.2069 | train_accuracy: 0.9453 | test_accuracy: 0.9512\n",
      "[  420/  468] train_loss: 0.1430 | train_accuracy: 0.9531 | test_accuracy: 0.9515\n",
      "[  421/  468] train_loss: 0.3004 | train_accuracy: 0.9453 | test_accuracy: 0.9517\n",
      "[  422/  468] train_loss: 0.3527 | train_accuracy: 0.9609 | test_accuracy: 0.9519\n",
      "[  423/  468] train_loss: 0.1974 | train_accuracy: 0.9531 | test_accuracy: 0.9523\n",
      "[  424/  468] train_loss: 0.1761 | train_accuracy: 0.9375 | test_accuracy: 0.9532\n",
      "[  425/  468] train_loss: 0.2839 | train_accuracy: 0.9531 | test_accuracy: 0.9534\n",
      "[  426/  468] train_loss: 0.3284 | train_accuracy: 0.9453 | test_accuracy: 0.9544\n",
      "[  427/  468] train_loss: 0.2249 | train_accuracy: 0.9453 | test_accuracy: 0.9546\n",
      "[  428/  468] train_loss: 0.1476 | train_accuracy: 0.9766 | test_accuracy: 0.9545\n",
      "[  429/  468] train_loss: 0.1636 | train_accuracy: 0.9609 | test_accuracy: 0.9545\n",
      "[  430/  468] train_loss: 0.2445 | train_accuracy: 0.9844 | test_accuracy: 0.9534\n",
      "[  431/  468] train_loss: 0.2186 | train_accuracy: 0.9531 | test_accuracy: 0.9519\n",
      "[  432/  468] train_loss: 0.2642 | train_accuracy: 0.9375 | test_accuracy: 0.9509\n",
      "[  433/  468] train_loss: 0.2002 | train_accuracy: 0.9453 | test_accuracy: 0.9502\n",
      "[  434/  468] train_loss: 0.1927 | train_accuracy: 0.9688 | test_accuracy: 0.9487\n",
      "[  435/  468] train_loss: 0.1961 | train_accuracy: 0.9453 | test_accuracy: 0.9498\n",
      "[  436/  468] train_loss: 0.2631 | train_accuracy: 0.9219 | test_accuracy: 0.9502\n",
      "[  437/  468] train_loss: 0.2897 | train_accuracy: 0.9141 | test_accuracy: 0.9514\n",
      "[  438/  468] train_loss: 0.1416 | train_accuracy: 0.9688 | test_accuracy: 0.9530\n",
      "[  439/  468] train_loss: 0.1823 | train_accuracy: 0.9688 | test_accuracy: 0.9542\n",
      "[  440/  468] train_loss: 0.3178 | train_accuracy: 0.9531 | test_accuracy: 0.9538\n",
      "[  441/  468] train_loss: 0.2098 | train_accuracy: 0.9531 | test_accuracy: 0.9540\n",
      "[  442/  468] train_loss: 0.1186 | train_accuracy: 0.9609 | test_accuracy: 0.9537\n",
      "[  443/  468] train_loss: 0.1970 | train_accuracy: 0.9688 | test_accuracy: 0.9533\n",
      "[  444/  468] train_loss: 0.2370 | train_accuracy: 0.9609 | test_accuracy: 0.9528\n",
      "[  445/  468] train_loss: 0.1865 | train_accuracy: 0.9609 | test_accuracy: 0.9515\n",
      "[  446/  468] train_loss: 0.3127 | train_accuracy: 0.9609 | test_accuracy: 0.9524\n",
      "[  447/  468] train_loss: 0.2925 | train_accuracy: 0.9375 | test_accuracy: 0.9531\n",
      "[  448/  468] train_loss: 0.3159 | train_accuracy: 0.9297 | test_accuracy: 0.9524\n",
      "[  449/  468] train_loss: 0.2476 | train_accuracy: 0.9609 | test_accuracy: 0.9527\n",
      "[  450/  468] train_loss: 0.3249 | train_accuracy: 0.9453 | test_accuracy: 0.9534\n",
      "[  451/  468] train_loss: 0.2921 | train_accuracy: 0.9609 | test_accuracy: 0.9536\n",
      "[  452/  468] train_loss: 0.1959 | train_accuracy: 0.9453 | test_accuracy: 0.9552\n",
      "[  453/  468] train_loss: 0.2095 | train_accuracy: 0.9688 | test_accuracy: 0.9551\n",
      "[  454/  468] train_loss: 0.1771 | train_accuracy: 0.9766 | test_accuracy: 0.9544\n",
      "[  455/  468] train_loss: 0.2275 | train_accuracy: 0.9609 | test_accuracy: 0.9547\n",
      "[  456/  468] train_loss: 0.1759 | train_accuracy: 0.9609 | test_accuracy: 0.9548\n",
      "[  457/  468] train_loss: 0.2629 | train_accuracy: 0.9453 | test_accuracy: 0.9557\n",
      "[  458/  468] train_loss: 0.4200 | train_accuracy: 0.9375 | test_accuracy: 0.9559\n",
      "[  459/  468] train_loss: 0.3097 | train_accuracy: 0.9453 | test_accuracy: 0.9575\n",
      "[  460/  468] train_loss: 0.1919 | train_accuracy: 0.9531 | test_accuracy: 0.9573\n",
      "[  461/  468] train_loss: 0.1957 | train_accuracy: 0.9844 | test_accuracy: 0.9570\n",
      "[  462/  468] train_loss: 0.1678 | train_accuracy: 0.9766 | test_accuracy: 0.9562\n",
      "[  463/  468] train_loss: 0.3045 | train_accuracy: 0.9766 | test_accuracy: 0.9557\n",
      "[  464/  468] train_loss: 0.1334 | train_accuracy: 0.9844 | test_accuracy: 0.9563\n",
      "[  465/  468] train_loss: 0.2954 | train_accuracy: 0.9375 | test_accuracy: 0.9565\n",
      "[  466/  468] train_loss: 0.3066 | train_accuracy: 0.9453 | test_accuracy: 0.9574\n",
      "[  467/  468] train_loss: 0.2379 | train_accuracy: 0.9531 | test_accuracy: 0.9595\n",
      "[  468/  468] train_loss: 0.2444 | train_accuracy: 0.9609 | test_accuracy: 0.9583\n",
      "[  469/  468] train_loss: 0.1648 | train_accuracy: 0.9609 | test_accuracy: 0.9575\n",
      "[  470/  468] train_loss: 0.1704 | train_accuracy: 0.9844 | test_accuracy: 0.9559\n",
      "[  471/  468] train_loss: 0.3166 | train_accuracy: 0.9375 | test_accuracy: 0.9562\n",
      "[  472/  468] train_loss: 0.2152 | train_accuracy: 0.9453 | test_accuracy: 0.9547\n",
      "[  473/  468] train_loss: 0.1251 | train_accuracy: 0.9766 | test_accuracy: 0.9550\n",
      "[  474/  468] train_loss: 0.2061 | train_accuracy: 0.9688 | test_accuracy: 0.9567\n",
      "[  475/  468] train_loss: 0.2630 | train_accuracy: 0.9609 | test_accuracy: 0.9584\n",
      "[  476/  468] train_loss: 0.2567 | train_accuracy: 0.9688 | test_accuracy: 0.9583\n",
      "[  477/  468] train_loss: 0.1312 | train_accuracy: 0.9922 | test_accuracy: 0.9580\n",
      "[  478/  468] train_loss: 0.1877 | train_accuracy: 0.9453 | test_accuracy: 0.9571\n",
      "[  479/  468] train_loss: 0.1240 | train_accuracy: 0.9766 | test_accuracy: 0.9550\n",
      "[  480/  468] train_loss: 0.1983 | train_accuracy: 0.9688 | test_accuracy: 0.9547\n",
      "[  481/  468] train_loss: 0.1517 | train_accuracy: 0.9844 | test_accuracy: 0.9528\n",
      "[  482/  468] train_loss: 0.3232 | train_accuracy: 0.9531 | test_accuracy: 0.9530\n",
      "[  483/  468] train_loss: 0.2605 | train_accuracy: 0.9844 | test_accuracy: 0.9540\n",
      "[  484/  468] train_loss: 0.1504 | train_accuracy: 0.9844 | test_accuracy: 0.9545\n",
      "[  485/  468] train_loss: 0.2380 | train_accuracy: 0.9766 | test_accuracy: 0.9549\n",
      "[  486/  468] train_loss: 0.1838 | train_accuracy: 0.9453 | test_accuracy: 0.9555\n",
      "[  487/  468] train_loss: 0.3280 | train_accuracy: 0.9609 | test_accuracy: 0.9564\n",
      "[  488/  468] train_loss: 0.1681 | train_accuracy: 0.9688 | test_accuracy: 0.9566\n",
      "[  489/  468] train_loss: 0.3035 | train_accuracy: 0.9531 | test_accuracy: 0.9572\n",
      "[  490/  468] train_loss: 0.2251 | train_accuracy: 0.9453 | test_accuracy: 0.9563\n",
      "[  491/  468] train_loss: 0.3419 | train_accuracy: 0.9531 | test_accuracy: 0.9561\n",
      "[  492/  468] train_loss: 0.2925 | train_accuracy: 0.9297 | test_accuracy: 0.9558\n",
      "[  493/  468] train_loss: 0.1866 | train_accuracy: 0.9609 | test_accuracy: 0.9562\n",
      "[  494/  468] train_loss: 0.3873 | train_accuracy: 0.9297 | test_accuracy: 0.9560\n",
      "[  495/  468] train_loss: 0.3165 | train_accuracy: 0.9375 | test_accuracy: 0.9556\n",
      "[  496/  468] train_loss: 0.2090 | train_accuracy: 0.9844 | test_accuracy: 0.9574\n",
      "[  497/  468] train_loss: 0.4151 | train_accuracy: 0.9453 | test_accuracy: 0.9581\n",
      "[  498/  468] train_loss: 0.2365 | train_accuracy: 0.9453 | test_accuracy: 0.9590\n",
      "[  499/  468] train_loss: 0.2124 | train_accuracy: 0.9766 | test_accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  500/  468] train_loss: 0.2105 | train_accuracy: 0.9688 | test_accuracy: 0.9556\n",
      "[  501/  468] train_loss: 0.1199 | train_accuracy: 0.9844 | test_accuracy: 0.9545\n",
      "[  502/  468] train_loss: 0.2029 | train_accuracy: 0.9609 | test_accuracy: 0.9529\n",
      "[  503/  468] train_loss: 0.4400 | train_accuracy: 0.8906 | test_accuracy: 0.9520\n",
      "[  504/  468] train_loss: 0.1824 | train_accuracy: 0.9844 | test_accuracy: 0.9523\n",
      "[  505/  468] train_loss: 0.1747 | train_accuracy: 0.9531 | test_accuracy: 0.9533\n",
      "[  506/  468] train_loss: 0.2677 | train_accuracy: 0.9531 | test_accuracy: 0.9543\n",
      "[  507/  468] train_loss: 0.2422 | train_accuracy: 0.9453 | test_accuracy: 0.9557\n",
      "[  508/  468] train_loss: 0.1747 | train_accuracy: 0.9922 | test_accuracy: 0.9557\n",
      "[  509/  468] train_loss: 0.1673 | train_accuracy: 0.9844 | test_accuracy: 0.9569\n",
      "[  510/  468] train_loss: 0.2098 | train_accuracy: 0.9531 | test_accuracy: 0.9563\n",
      "[  511/  468] train_loss: 0.2242 | train_accuracy: 0.9531 | test_accuracy: 0.9571\n",
      "[  512/  468] train_loss: 0.1954 | train_accuracy: 0.9609 | test_accuracy: 0.9585\n",
      "[  513/  468] train_loss: 0.2833 | train_accuracy: 0.9766 | test_accuracy: 0.9580\n",
      "[  514/  468] train_loss: 0.1867 | train_accuracy: 0.9844 | test_accuracy: 0.9582\n",
      "[  515/  468] train_loss: 0.3724 | train_accuracy: 0.9609 | test_accuracy: 0.9587\n",
      "[  516/  468] train_loss: 0.1810 | train_accuracy: 0.9688 | test_accuracy: 0.9587\n",
      "[  517/  468] train_loss: 0.1868 | train_accuracy: 0.9609 | test_accuracy: 0.9581\n",
      "[  518/  468] train_loss: 0.3096 | train_accuracy: 0.9531 | test_accuracy: 0.9587\n",
      "[  519/  468] train_loss: 0.2583 | train_accuracy: 0.9531 | test_accuracy: 0.9592\n",
      "[  520/  468] train_loss: 0.2735 | train_accuracy: 0.9453 | test_accuracy: 0.9587\n",
      "[  521/  468] train_loss: 0.2524 | train_accuracy: 0.9531 | test_accuracy: 0.9592\n",
      "[  522/  468] train_loss: 0.2058 | train_accuracy: 0.9609 | test_accuracy: 0.9585\n",
      "[  523/  468] train_loss: 0.1691 | train_accuracy: 0.9609 | test_accuracy: 0.9572\n",
      "[  524/  468] train_loss: 0.1856 | train_accuracy: 0.9688 | test_accuracy: 0.9567\n",
      "[  525/  468] train_loss: 0.3465 | train_accuracy: 0.9609 | test_accuracy: 0.9563\n",
      "[  526/  468] train_loss: 0.1329 | train_accuracy: 0.9766 | test_accuracy: 0.9563\n",
      "[  527/  468] train_loss: 0.2185 | train_accuracy: 0.9531 | test_accuracy: 0.9559\n",
      "[  528/  468] train_loss: 0.2258 | train_accuracy: 0.9922 | test_accuracy: 0.9565\n",
      "[  529/  468] train_loss: 0.1226 | train_accuracy: 0.9844 | test_accuracy: 0.9566\n",
      "[  530/  468] train_loss: 0.2079 | train_accuracy: 0.9766 | test_accuracy: 0.9578\n",
      "[  531/  468] train_loss: 0.2862 | train_accuracy: 0.9375 | test_accuracy: 0.9587\n",
      "[  532/  468] train_loss: 0.1682 | train_accuracy: 0.9688 | test_accuracy: 0.9586\n",
      "[  533/  468] train_loss: 0.1715 | train_accuracy: 0.9766 | test_accuracy: 0.9581\n",
      "[  534/  468] train_loss: 0.2142 | train_accuracy: 0.9531 | test_accuracy: 0.9573\n",
      "[  535/  468] train_loss: 0.2640 | train_accuracy: 0.9375 | test_accuracy: 0.9574\n",
      "[  536/  468] train_loss: 0.2950 | train_accuracy: 0.9219 | test_accuracy: 0.9583\n",
      "[  537/  468] train_loss: 0.1908 | train_accuracy: 0.9688 | test_accuracy: 0.9586\n",
      "[  538/  468] train_loss: 0.1706 | train_accuracy: 0.9688 | test_accuracy: 0.9594\n",
      "[  539/  468] train_loss: 0.1477 | train_accuracy: 0.9766 | test_accuracy: 0.9602\n",
      "[  540/  468] train_loss: 0.1631 | train_accuracy: 0.9844 | test_accuracy: 0.9611\n",
      "[  541/  468] train_loss: 0.2579 | train_accuracy: 0.9609 | test_accuracy: 0.9614\n",
      "[  542/  468] train_loss: 0.2303 | train_accuracy: 0.9531 | test_accuracy: 0.9614\n",
      "[  543/  468] train_loss: 0.1535 | train_accuracy: 0.9688 | test_accuracy: 0.9605\n",
      "[  544/  468] train_loss: 0.2100 | train_accuracy: 0.9609 | test_accuracy: 0.9610\n",
      "[  545/  468] train_loss: 0.2657 | train_accuracy: 0.9688 | test_accuracy: 0.9614\n",
      "[  546/  468] train_loss: 0.1815 | train_accuracy: 0.9844 | test_accuracy: 0.9605\n",
      "[  547/  468] train_loss: 0.3658 | train_accuracy: 0.9531 | test_accuracy: 0.9604\n",
      "[  548/  468] train_loss: 0.2071 | train_accuracy: 0.9609 | test_accuracy: 0.9596\n",
      "[  549/  468] train_loss: 0.1410 | train_accuracy: 0.9922 | test_accuracy: 0.9594\n",
      "[  550/  468] train_loss: 0.2683 | train_accuracy: 0.9375 | test_accuracy: 0.9591\n",
      "[  551/  468] train_loss: 0.1990 | train_accuracy: 0.9609 | test_accuracy: 0.9591\n",
      "[  552/  468] train_loss: 0.1681 | train_accuracy: 0.9688 | test_accuracy: 0.9577\n",
      "[  553/  468] train_loss: 0.2760 | train_accuracy: 0.9609 | test_accuracy: 0.9568\n",
      "[  554/  468] train_loss: 0.2785 | train_accuracy: 0.9453 | test_accuracy: 0.9571\n",
      "[  555/  468] train_loss: 0.2012 | train_accuracy: 0.9688 | test_accuracy: 0.9578\n",
      "[  556/  468] train_loss: 0.2243 | train_accuracy: 0.9766 | test_accuracy: 0.9585\n",
      "[  557/  468] train_loss: 0.3042 | train_accuracy: 0.9766 | test_accuracy: 0.9590\n",
      "[  558/  468] train_loss: 0.1386 | train_accuracy: 0.9688 | test_accuracy: 0.9588\n",
      "[  559/  468] train_loss: 0.1753 | train_accuracy: 0.9688 | test_accuracy: 0.9592\n",
      "[  560/  468] train_loss: 0.1942 | train_accuracy: 0.9531 | test_accuracy: 0.9593\n",
      "[  561/  468] train_loss: 0.2055 | train_accuracy: 0.9688 | test_accuracy: 0.9581\n",
      "[  562/  468] train_loss: 0.2407 | train_accuracy: 0.9844 | test_accuracy: 0.9593\n",
      "[  563/  468] train_loss: 0.1413 | train_accuracy: 0.9844 | test_accuracy: 0.9588\n",
      "[  564/  468] train_loss: 0.1341 | train_accuracy: 0.9609 | test_accuracy: 0.9585\n",
      "[  565/  468] train_loss: 0.2506 | train_accuracy: 0.9375 | test_accuracy: 0.9575\n",
      "[  566/  468] train_loss: 0.1959 | train_accuracy: 0.9766 | test_accuracy: 0.9572\n",
      "[  567/  468] train_loss: 0.2878 | train_accuracy: 0.9453 | test_accuracy: 0.9570\n",
      "[  568/  468] train_loss: 0.1881 | train_accuracy: 0.9688 | test_accuracy: 0.9568\n",
      "[  569/  468] train_loss: 0.1311 | train_accuracy: 0.9844 | test_accuracy: 0.9559\n",
      "[  570/  468] train_loss: 0.3089 | train_accuracy: 0.9531 | test_accuracy: 0.9556\n",
      "[  571/  468] train_loss: 0.2419 | train_accuracy: 0.9609 | test_accuracy: 0.9565\n",
      "[  572/  468] train_loss: 0.1750 | train_accuracy: 0.9688 | test_accuracy: 0.9569\n",
      "[  573/  468] train_loss: 0.2559 | train_accuracy: 0.9453 | test_accuracy: 0.9564\n",
      "[  574/  468] train_loss: 0.1838 | train_accuracy: 0.9688 | test_accuracy: 0.9554\n",
      "[  575/  468] train_loss: 0.1375 | train_accuracy: 0.9766 | test_accuracy: 0.9548\n",
      "[  576/  468] train_loss: 0.2865 | train_accuracy: 0.9453 | test_accuracy: 0.9541\n",
      "[  577/  468] train_loss: 0.1551 | train_accuracy: 0.9688 | test_accuracy: 0.9549\n",
      "[  578/  468] train_loss: 0.2755 | train_accuracy: 0.9375 | test_accuracy: 0.9545\n",
      "[  579/  468] train_loss: 0.3597 | train_accuracy: 0.9375 | test_accuracy: 0.9543\n",
      "[  580/  468] train_loss: 0.3290 | train_accuracy: 0.9531 | test_accuracy: 0.9547\n",
      "[  581/  468] train_loss: 0.1883 | train_accuracy: 0.9453 | test_accuracy: 0.9541\n",
      "[  582/  468] train_loss: 0.1947 | train_accuracy: 0.9766 | test_accuracy: 0.9540\n",
      "[  583/  468] train_loss: 0.2518 | train_accuracy: 0.9531 | test_accuracy: 0.9533\n",
      "[  584/  468] train_loss: 0.2950 | train_accuracy: 0.9453 | test_accuracy: 0.9537\n",
      "[  585/  468] train_loss: 0.1648 | train_accuracy: 0.9766 | test_accuracy: 0.9559\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-91d332bbf538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\son\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\son\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\son\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\son\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNextSync\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   2470\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network = model(label_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "iterations = len(train_data) // batch_size\n",
    "\n",
    "print(iterations)\n",
    "\n",
    "for idx, (train_x, train_label) in enumerate(train_dataset):\n",
    "    grads = grad(network, train_x, train_label)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
    "    \n",
    "    train_loss = loss_fn(network, train_x, train_label)\n",
    "    train_accuracy = accuracy_fn(network, train_x, train_label)\n",
    "    \n",
    "    for test_x, test_label in test_dataset:\n",
    "        test_accuracy = accuracy_fn(network, test_x, test_label)\n",
    "    \n",
    "    print('[{:5d}/{:5d}] train_loss: {:2.4f} | train_accuracy: {:2.4f} | test_accuracy: {:2.4f}'.format(idx, iterations, train_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
